{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a94b1429-1a64-49e8-b307-67bb84b3ee81",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Agent driven Auto Insurance Claims RAG Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9e82834-2dc6-4702-a25f-5794e7de14a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### In this notebook, I'll demonstrate how to leverage Azure AI Document Intelligence in conjunction with AzureOpenAI's multimodal GPT-4o model to extract and interpret data from auto insurance claim documents that feature intricate tables. I'll utilize a template form that includes detailed sections on accident location, incident description, involved vehicles, and injury information.\n",
    "#### I compare the responses to my sample questions against some ground truths, and so far, the answers are both accurate and relevant. Further refining the responses can be accomplished by applying additional preprocessing to the claims documents to better maintain context between the tables and associated texts. \n",
    "#### The claims files are in PDF format and contain tabular data.Azure AI Document Intelligence parses the table data into markdown-formatted tables, which can be chunked, indexed, uploaded to and queried over with a Azure AI Search index.\n",
    "#### The goal of this proof of concept is to demonstrate how insurance companies can expedite the process of extracting information from car accident insurance claim documents. This can be achieved without the need to manually read through each claims form.\n",
    "#### I set up autogen agents, incorporating a human-in-the-loop feature for automated chat interactions and responses.\n",
    "#### Out of the 6 questions, 4 were accurate, one was incomplete, and the last could not be answered.\n",
    "![Auto Insurance Claims Form in RAG](https://github.com/jbernec/rag-orchestrations/blob/main/images/claims-sample.jpeg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc213106-2f85-4540-9b86-cbb9beb2f5e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 1: Import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b2e0768-aab8-4642-bf01-71be5b08041f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, AnalyzeDocumentRequest, ContentFormat\n",
    "import time\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import get_bearer_token_provider\n",
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from autogen import AssistantAgent, UserProxyAgent, register_function\n",
    "from typing_extensions import List, Annotated\n",
    "import autogen\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchField, SearchFieldDataType, VectorSearch, SimpleField, SearchableField, HnswAlgorithmConfiguration, HnswParameters, VectorSearchAlgorithmMetric, ExhaustiveKnnAlgorithmConfiguration, ExhaustiveKnnParameters, VectorSearchProfile, AzureOpenAIVectorizer, AzureOpenAIParameters, SemanticConfiguration, SemanticSearch, SemanticPrioritizedFields, SemanticField, SearchIndex\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3debcf4e-262a-4ceb-8273-6bff9948e04a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 2: Set credential variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8b473b-62a8-4ca9-a2eb-0e1273057b92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads and sets the necessary variables for Azure services.\n",
    "The variables are loaded from Azure Key Vault.\n",
    "\"\"\"\n",
    "\n",
    "azure_openai_endpoint=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\")\n",
    "azure_openai_api_key=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\")\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "azure_openai_embedding_deployment = dbutils.secrets.get(scope=\"myscope\", key=\"aoai-embedding-deployment\")\n",
    "doc_intelligence_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-endpoint\")\n",
    "doc_intelligence_key = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-key\")\n",
    "search_credential = AzureKeyCredential(dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-adminkey\"))\n",
    "search_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0970805a-ca60-4687-908c-832e3d252999",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 3: Connect to blob storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29f9fd4e-db33-4260-9d5e-507876264871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Connect to Blob Storage\n",
    "blob_connection_string = dbutils.secrets.get(scope=\"myscope\", key=\"blobstore-connstr\")\n",
    "blob_container_name = \"insurance-rag\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "blobs = container_client.list_blobs()\n",
    "container_url = container_client.url\n",
    "#print(container_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e60a9a5b-439e-4b29-a12d-a73f07504425",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 4: Define and Configure Autogen Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89233432-d0f0-43e7-bd95-9ba8c8815d93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-deploymentname\"),\n",
    "            \"api_key\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\"),\n",
    "            \"base_url\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\"),\n",
    "            \"api_type\": \"azure\",\n",
    "            \"api_version\": \"2024-02-15-preview\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "gpt4_config = {\n",
    "    \"cache_seed\": 42,\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": llm_config[\"config_list\"],\n",
    "    \"timeout\": 120\n",
    "}\n",
    "\n",
    "\n",
    "ai_search_agent = AssistantAgent(\n",
    "    name=\"AISearchAssistant\",\n",
    "    system_message=\"You are a helpful AI agent.\"\n",
    "    \"You can help with Azure AI Search service.\"\n",
    "    \"Return TERMINATE when the task is done\",\n",
    "    llm_config=gpt4_config,\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    is_termination_msg=lambda x: \"terminate\" in x.get(\"content\", \"\").lower()\n",
    "    if x.get(\"content\", \"\") is not None\n",
    "    else False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e06881b-573a-456e-986f-e329e83cbc0c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 5: Define required functions and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c55004-2cbe-468e-aad8-49bb65eb4ddc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Function to convert text to unique random id for search index field\n",
    "def text_to_base64(text):\n",
    "    # Convert text to bytes using UTF-8 encoding\n",
    "    bytes_data = text.encode('utf-8')\n",
    "\n",
    "    # Perform Base64 encoding\n",
    "    base64_encoded = base64.b64encode(bytes_data)\n",
    "\n",
    "    # Convert the result back to a UTF-8 string representation\n",
    "    base64_text = base64_encoded.decode('utf-8')\n",
    "\n",
    "    return base64_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to crack and extract PDF documents using Azure AI Document Intelligence\n",
    "def extract_pdf_content(book_url: str):\n",
    "    page_documents = \"\"\n",
    "    print(f\"{book_url}\\n\\n\")\n",
    "    print(f\"---------------------------------------------\")\n",
    "    \n",
    "    document_intelligence_client = DocumentIntelligenceClient(endpoint=doc_intelligence_endpoint, credential=AzureKeyCredential(key=doc_intelligence_key))\n",
    "\n",
    "    poller= document_intelligence_client.begin_analyze_document(model_id=\"prebuilt-layout\", analyze_request=AnalyzeDocumentRequest(url_source=book_url), output_content_format=\"markdown\")\n",
    "\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    \n",
    "    for page in result.pages:\n",
    "        page_num = page.page_number\n",
    "        # Calculate the start position as the offset of the first span\n",
    "        start_pos = page.spans[0].offset\n",
    "\n",
    "        # Calculate the end position by adding the length of the first span to its offset\n",
    "        end_pos = start_pos + page.spans[0].length\n",
    "\n",
    "        # Slice the result.content string from start_pos to end_pos to get the desired content\n",
    "        page_content = result.content[start_pos:end_pos]\n",
    "        #print(f\"{page_content}\\n\\n\")\n",
    "\n",
    "        #print(f\"------------------------------------------\")\n",
    "        page_documents+=page_content\n",
    "\n",
    "    \n",
    "    return page_documents\n",
    "\n",
    "# Define chunk strategy function\n",
    "def chunk_text(text: str):\n",
    "    pass\n",
    "    recursive_text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        model_name=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-deploymentname\"),\n",
    "        chunk_size=600,\n",
    "        chunk_overlap=125,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    recursive_text_splitter_chunks = recursive_text_splitter.split_text(text=text)\n",
    "    return recursive_text_splitter_chunks\n",
    "\n",
    "# one way of registering functions is to use the register_for_llm and register_for_execution decorators or use the register_function method.\n",
    "\n",
    "@user_proxy.register_for_execution()\n",
    "@ai_search_agent.register_for_llm(\n",
    "    description=\"A tool or function for search retrieval from Azure AI Search\"\n",
    ")\n",
    "def search_retrieval(user_input:str) -> str:\n",
    "        \"\"\"\n",
    "        Search and retrieve answers from Azure AI Search.\n",
    "        Returns:\n",
    "            str\n",
    "        \"\"\"\n",
    "        query = user_input\n",
    "        search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "        vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=5, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "        r = search_client.search(  \n",
    "        search_text=query,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\", \"content\"],\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name='my-semantic-config',\n",
    "        query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "        query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=1\n",
    "    )\n",
    "        #query_result = results.get_answers()[0].text\n",
    "        results = [doc[\"content\"].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "        content = \"\\n\".join(results)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ca0b88a-1c99-4c67-8183-8fd073b118a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 6: Create Azure AI Search Index and Vector Configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea172d55-824d-49f8-ab03-4584a6898afc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the search index fields and vector search configuration\n",
    "\n",
    "# Create a search index client required to create the index\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", key=True, type=SearchFieldDataType.String, filterable=True, sortable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, filterable=True, searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True, sortable=True, facetable=True, retrievable=True),\n",
    "    SearchableField(name=\"location\", type=SearchFieldDataType.String, searchable=True, filterable=True, retrievable=True),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, retrievable=True, hidden=False, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "]\n",
    "\n",
    "# Configure the vector search config\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),\n",
    "    ],\n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_deployment,  \n",
    "                api_key=azure_openai_api_key,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure semantic search on the index\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[\n",
    "            SemanticField(field_name=\"content\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# Create the semantic search config\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index\n",
    "index_name = \"insuracer-rag-index\"\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index=index)\n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8edb88d-d1d8-4521-b85a-a03f72b2f64c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 7: Configure vector embeddings and extract document text, tables and images into markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ec9dd5a-23f7-4cca-b15d-3bb4a40bdf8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the langchain azure open ai embedding object. This will be used to embed the vector field content\n",
    "# https://python.langchain.com/v0.1/docs/integrations/vectorstores/azuresearch/#create-embeddings-and-vector-store-instances\n",
    "\n",
    "# Create azure open ai embedding\n",
    "azure_openai_client = None\n",
    "if azure_openai_api_key:\n",
    "    azure_openai_client = AzureOpenAI(\n",
    "        api_key=azure_openai_api_key, \n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_deployment=azure_openai_embedding_deployment,\n",
    "        azure_endpoint=azure_openai_endpoint)\n",
    "else:\n",
    "    azure_openai_client = AzureOpenAI(\n",
    "        azure_ad_token_provider=get_bearer_token_provider(DefaultAzureCredential(), scope=\"https://cognitiveservices.azure.com/.default\"),\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_deployment=azure_openai_embedding_deployment,\n",
    "        azure_endpoint=azure_openai_endpoint)\n",
    "    \n",
    "\n",
    "aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")\n",
    "\n",
    "# dictionary to hold and map a book to it's content and page numbers\n",
    "claims_pages_map = {}\n",
    "\n",
    "for claim in container_client.list_blob_names():\n",
    "    print(f\"Extracting content from {claim}...\")\n",
    "\n",
    "    # Capture the start time\n",
    "    start_time = time.time()\n",
    "    book_url = container_url + \"/\" + claim\n",
    "\n",
    "    # Start extraction\n",
    "    page_documents = extract_pdf_content(book_url=book_url)\n",
    "    claim_name = claim.split(sep=\".\")[0].title()\n",
    "    chunks = chunk_text(page_documents)\n",
    "    #chunked_docs = [Document(page_content=chunk) for chunk in chunks]\n",
    "    claims_pages_map[claim_name]= chunks\n",
    "\n",
    "    # Capture the end time and Calculate the elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
    "    print(f\"The {claim_name} book contains {len(chunks)} chunks\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc3ee094-0109-4870-9681-6ab25036edad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 8: Upload documents into Azure AI Search Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "650a4fb6-5f4a-4d55-a187-f789d2ffd310",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, credential=search_credential)\n",
    "\n",
    "for claimname, chunks in claims_pages_map.items():\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            id = claimname + chunk[1:10]\n",
    "            title = f\"{claimname}\"\n",
    "            upload_payload = {\n",
    "                        \"id\": text_to_base64(text=id),\n",
    "                        \"title\": title,\n",
    "                        \"content\": chunk,\n",
    "                        \"location\": container_url + \"/\" + claimname + \".pdf\",\n",
    "                        \"vector\": aoai_embeddings.embed_query(chunk if chunk!=\"\" else \"-------\")\n",
    "            }\n",
    "\n",
    "            result_upload = search_client.upload_documents(documents=[upload_payload])\n",
    "            #print(f\"Successfully uploaded chunk for :{bookname}\")\n",
    "        except Exception as e:\n",
    "            print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "837b5a0c-7575-4c7f-863b-62466adf908b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 9: Initiate Agent based Chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cac2a6f-5170-4ce1-b3e8-2c71c8759f4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message = \"Search for 'How did Ms. Patel's accident happen' in the above defined index?\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec62643-22a3-4906-a46a-bdb2d63fa9f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_2 = \"Search for 'Who filed the insurance claim for the accident that happened on Sunset Blvd?' in the above defined index\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60347a2f-e705-4e73-9571-e2f131c18610",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_3 = \"Search for 'Given the accident that happened on Lombard Street, name a party that is liable for the damages and explain why.' in the above defined index\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0626a1a2-5b4a-4cd1-a82d-c0cf37d30d8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_4 = \"Search for 'Did Ms. Johnson sustain any injuries? If so, what were those injuries?' in the above defined index\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71f02f3b-b670-4f8e-8bde-0243ea71d5b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_5 = \"Search for 'Who are some witnesses for the Ms. Patel's accident and how can we contact them?' in the above defined index\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "572e27d5-823c-49e1-bda9-6942bb664df0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_6 = \"Search for 'How was Mr. Johnson's red sedan damaged?Give me details? What's the repair cost?' in the above defined index\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_6)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "insurance-claims-agent-based-rag",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
