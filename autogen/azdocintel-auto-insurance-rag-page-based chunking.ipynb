{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d221024-5a24-48c9-a668-93d12c41970c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Autogen Agent-driven Auto Insurance Claims RAG Pipeline with Page-based chunking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f02825e-aab6-403c-9a51-b85b628f1c76",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### RAG has developed as a new data stack that differs from traditional ETL. While it still involves data ingestion and processing like traditional ETL, it also incorporates extra pipeline steps such as chunking, embedding, and loading data into a vector database.\n",
    "#### The main objective of these new RAG pipelines is to enable context-augmented LLM applications. \n",
    "#### In this notebook, I'll demonstrate how to leverage Azure AI Document Intelligence in conjunction with AzureOpenAI's multimodal GPT-4o model to extract and interpret data from auto insurance claims documents that feature intricate tables. I'll utilize a template form that includes detailed sections on accident location, incident description, involved vehicles, and injury information.\n",
    "#### I implemented a page-based chunking, by extracting each page in the Azure AI Document Intelligence ingest result object and configuring it as it's own chunk with all the extracted content and markdown tabular data.In addition, I extracted all table objects and metadata separately and uploaded as one chunk.I will evaluate the results of the downstream llm agent responses against that the results from previous PoCs built uisng other strategies.\n",
    "#### I compare the responses to my sample questions against some ground truths, and so far, the answers are both accurate and relevant. Further refinement of the responses can be accomplished by applying additional preprocessing to the claims documents to better maintain context between the tables and associated texts. \n",
    "#### The claims files are in PDF format and contain tabular data.Azure AI Document Intelligence parses the table data into markdown-formatted tables, which can be chunked, indexed, uploaded to and queried over with a Azure AI Search index.\n",
    "#### The goal of this proof of concept is to demonstrate how insurance companies can expedite the process of extracting information from car accident insurance claim documents. This can be achieved without the need to manually read through each claims form.\n",
    "#### I set up autogen agents, incorporating a human-in-the-loop feature for automated chat interactions and responses.\n",
    "#### Out of the 6 questions, 4 were accurate, one was incomplete, and the last could not be answered.\n",
    "![Auto Insurance Claims Form in RAG](https://github.com/jbernec/rag-orchestrations/blob/main/images/claims-sample.jpeg?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec7358e-9280-4cce-b38a-19b6b52531ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, AnalyzeDocumentRequest, ContentFormat\n",
    "import time\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import get_bearer_token_provider\n",
    "from autogen import AssistantAgent, UserProxyAgent, register_function\n",
    "from typing_extensions import List, Annotated\n",
    "import autogen\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchField, SearchFieldDataType, VectorSearch, SimpleField, SearchableField, HnswAlgorithmConfiguration, HnswParameters, VectorSearchAlgorithmMetric, ExhaustiveKnnAlgorithmConfiguration, ExhaustiveKnnParameters, VectorSearchProfile, AzureOpenAIVectorizer, AzureOpenAIParameters, SemanticConfiguration, SemanticSearch, SemanticPrioritizedFields, SemanticField, SearchIndex\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23e798f2-e8f7-4c39-9a0b-1cb32b6d3a62",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 2: Set credential variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "778616df-fd86-493f-90c0-8537805488e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads and sets the necessary variables for Azure services.\n",
    "The variables are loaded from Azure Key Vault.\n",
    "\"\"\"\n",
    "azure_openai_endpoint=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\")\n",
    "azure_openai_api_key=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\")\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "azure_openai_embedding_deployment = dbutils.secrets.get(scope=\"myscope\", key=\"aoai-embedding-deployment\")\n",
    "doc_intelligence_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-endpoint\")\n",
    "doc_intelligence_key = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-key\")\n",
    "search_credential = AzureKeyCredential(dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-adminkey\"))\n",
    "search_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-endpoint\")\n",
    "index_name = \"azdocintel-insurance-index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "799fc4a9-d809-4419-b7a4-bddb0677cf60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 3: Connect to blob storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65706cdf-bc00-4344-98d9-cd4171ffad4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Connect to Blob Storage\n",
    "blob_connection_string = dbutils.secrets.get(scope=\"myscope\", key=\"blobstore-connstr\")\n",
    "blob_container_name = \"insurance-rag\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "blobs = container_client.list_blobs()\n",
    "container_url = container_client.url\n",
    "print(container_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86d83597-dd38-4a93-8e48-bcd862e945d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 4: Define and Configure Autogen Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdf6347-b31d-4aa7-8ba2-e12b8deb01bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-deploymentname\"),\n",
    "            \"api_key\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\"),\n",
    "            \"base_url\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\"),\n",
    "            \"api_type\": \"azure\",\n",
    "            \"api_version\": \"2024-02-15-preview\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "gpt4_config = {\n",
    "    \"cache_seed\": 42,\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": llm_config[\"config_list\"],\n",
    "    \"timeout\": 120\n",
    "}\n",
    "\n",
    "\n",
    "ai_search_agent = AssistantAgent(\n",
    "    name=\"AISearchAssistant\",\n",
    "    system_message=\"You are a helpful AI agent.\"\n",
    "    \"You can help with Azure AI Search service.\"\n",
    "    \"Return TERMINATE when the task is done\",\n",
    "    llm_config=gpt4_config,\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    is_termination_msg=lambda x: \"terminate\" in x.get(\"content\", \"\").lower()\n",
    "    if x.get(\"content\", \"\") is not None\n",
    "    else False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39046672-2ff3-46d4-bbdb-d7c0dfb79ca2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 5: Define required functions and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "896f80fe-21ee-4cb3-802d-e364d971e100",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Function to convert text to unique random id for search index field\n",
    "def text_to_base64(text):\n",
    "    # Convert text to bytes using UTF-8 encoding\n",
    "    bytes_data = text.encode('utf-8')\n",
    "\n",
    "    # Perform Base64 encoding\n",
    "    base64_encoded = base64.b64encode(bytes_data)\n",
    "\n",
    "    # Convert the result back to a UTF-8 string representation\n",
    "    base64_text = base64_encoded.decode('utf-8')\n",
    "\n",
    "    return base64_text\n",
    "\n",
    "\n",
    "def extract_pdf_tables(book_url: str):\n",
    "    tables_on_page = []\n",
    "    if result.tables:\n",
    "        for table in result.tables:\n",
    "            tables_on_page.append(table)\n",
    "        return tables_on_page\n",
    "\n",
    "# Function to crack and extract PDF documents using Azure AI Document Intelligence\n",
    "def extract_pdf_pages(book_url: str):\n",
    "    page_list = []\n",
    "    print(f\"{book_url}\\n\\n\")\n",
    "    print(f\"---------------------------------------------\")\n",
    "    \n",
    "    document_intelligence_client = DocumentIntelligenceClient(endpoint=doc_intelligence_endpoint, credential=AzureKeyCredential(key=doc_intelligence_key))\n",
    "\n",
    "    poller= document_intelligence_client.begin_analyze_document(model_id=\"prebuilt-layout\", analyze_request=AnalyzeDocumentRequest(url_source=book_url), output_content_format=\"markdown\")\n",
    "\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    \n",
    "    for page in result.pages:\n",
    "        page_num = page.page_number\n",
    "        page_content = \"\"\n",
    "        #tables_on_page = [table for table in result.tables if table.bounding_regions[0].page_number == page_num]\n",
    "        # Calculate the start position as the offset of the first span\n",
    "        start_pos = page.spans[0].offset\n",
    "\n",
    "        # Calculate the end position by adding the length of the first span to its offset\n",
    "        end_pos = start_pos + page.spans[0].length\n",
    "\n",
    "        # Slice the result.content string from start_pos to end_pos to get the desired content\n",
    "        page_content += result.content[start_pos:end_pos]\n",
    "        #print(f\"{page_content}\\n\\n\")\n",
    "        page_content += \" \"\n",
    "        page_list.append((page_num, page_content))\n",
    "\n",
    "    \n",
    "    return page_list\n",
    "\n",
    "# one way of registering functions is to use the register_for_llm and register_for_execution decorators or use the register_function method.\n",
    "\n",
    "@user_proxy.register_for_execution()\n",
    "@ai_search_agent.register_for_llm(\n",
    "    description=\"A tool or function for search retrieval from Azure AI Search\"\n",
    ")\n",
    "def search_retrieval(user_input:str) -> str:\n",
    "        \"\"\"\n",
    "        Search and retrieve answers from Azure AI Search.\n",
    "        Returns:\n",
    "            str\n",
    "        \"\"\"\n",
    "        query = user_input\n",
    "        search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "        vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=5, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "        r = search_client.search(  \n",
    "        search_text=query,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\", \"content\"],\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name='my-semantic-config',\n",
    "        query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "        query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=1\n",
    "    )\n",
    "        #query_result = results.get_answers()[0].text\n",
    "        results = [doc[\"content\"].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "        content = \"\\n\".join(results)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b1b8e50-2618-43b9-8795-2e140f82e3d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 6: Create Azure AI Search Index and Vector Configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b06e1d-cad5-4776-9cfe-c2162819b6a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the search index fields and vector search configuration\n",
    "\n",
    "# Create a search index client required to create the index\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", key=True, type=SearchFieldDataType.String, filterable=True, sortable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, filterable=True, searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True, sortable=True, facetable=True, retrievable=True),\n",
    "    SearchableField(name=\"location\", type=SearchFieldDataType.String, searchable=True, filterable=True, retrievable=True),\n",
    "    SearchableField(name=\"pagenum\", type=SearchFieldDataType.String, searchable=True, filterable=True, retrievable=True),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, retrievable=True, hidden=False, vector_search_dimensions=1536, vector_search_profile_name=\"myExhaustiveKnnProfile\")\n",
    "]\n",
    "\n",
    "# Configure the vector search config\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        ),\n",
    "        ExhaustiveKnnAlgorithmConfiguration(\n",
    "                name=\"myExhaustiveKnn\",\n",
    "                parameters=ExhaustiveKnnParameters(\n",
    "                    metric=VectorSearchAlgorithmMetric.COSINE\n",
    "                ),\n",
    "            )\n",
    "    ],\n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "                name=\"myExhaustiveKnnProfile\",\n",
    "                algorithm_configuration_name=\"myExhaustiveKnn\",\n",
    "                vectorizer=\"myOpenAI\",\n",
    "            )\n",
    "    ],\n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_deployment,  \n",
    "                api_key=azure_openai_api_key,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure semantic search on the index\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[\n",
    "            SemanticField(field_name=\"content\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# Create the semantic search config\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index=index)\n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b868a8a3-69b9-4c60-8a68-6427426ab446",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 7: Configure vector embeddings and extract document text, tables and images into markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b4fb4d3-f99d-4b17-a976-3ac9dcc3b178",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the azure open ai embedding object. This will be used to embed the vector content/chunk field\n",
    "\n",
    "\n",
    "# Instantiate azure open ai embedding\n",
    "\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    api_key=azure_openai_api_key,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    ")\n",
    "\n",
    "\n",
    "aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")\n",
    "\n",
    "# dictionary to hold and map a book to it's content and page numbers\n",
    "claims_doc_map = {}\n",
    "\n",
    "for claim_doc in container_client.list_blob_names():\n",
    "    print(f\"Extracting content from {claim_doc}...\")\n",
    "\n",
    "    # Capture the start time\n",
    "    start_time = time.time()\n",
    "    book_url = container_url + \"/\" + claim_doc\n",
    "\n",
    "    # Start extraction\n",
    "    page_list = extract_pdf_pages(book_url=book_url)\n",
    "    claim_doc_name = claim_doc.split(sep=\".\")[0].title()\n",
    "    claims_doc_map[claim_doc_name] = page_list\n",
    "\n",
    "    # Capture the end time and Calculate the elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
    "    print(f\"The {claim_doc_name} claim contains {len(page_list)} pages\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "086197f9-3051-4c93-99ab-8585fb9881e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 8: Upload documents into Azure AI Search Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "402665db-492a-4b28-82cd-750f12aa917b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, credential=search_credential)\n",
    "payload_list = []\n",
    "for claimdoc, pagelist in claims_doc_map.items():\n",
    "    for page in pagelist:\n",
    "        try:\n",
    "            id = claimdoc + page[1][1:10]\n",
    "            title = f\"{claimdoc}\"\n",
    "            upload_payload = {\n",
    "                        \"id\": text_to_base64(text=id),\n",
    "                        \"title\": title,\n",
    "                        \"content\": page[1],\n",
    "                        \"location\": container_url + \"/\" + claimdoc + \".pdf\",\n",
    "                        \"pagenum\": str(page[0]),\n",
    "                        \"vector\": aoai_embeddings.embed_query(page[1] if page[1]!=\"\" else \"-------\")\n",
    "            }\n",
    "            payload_list.append(upload_payload)\n",
    "            print(f\"Uploading pages.............for :{claimdoc}\")\n",
    "            result_upload = search_client.upload_documents(documents=[upload_payload])\n",
    "            print(f\"Successfully uploaded pages for :{claimdoc}\")\n",
    "        except Exception as e:\n",
    "            print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ac2d7c9-0075-4bb2-b0e3-e3964870ff7e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 9: Initiate Agent based Chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c324520-542d-48d1-bff5-7390b24d6a0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_1 = \"Search for 'Who filed the insurance claim for the accident that happened on Sunset Blvd?' in the above defined index?\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e969dd30-8722-48d3-86c0-a31ef14b3f6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_2 = \"Search for 'How did Ms. Patel's accident happen?' in the above defined index?\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6c041da-fcf3-4fee-bb21-eecd2f62acb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_3 = \"Search for 'Was a red sedan damaged and how?' in the above defined index?\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3312a16-4210-4aaf-b62c-4801ef495e8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_4 = \"Search for 'How was Mr. Doe's car damaged?' in the above defined index?\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6368b4fb-4ddc-4b4c-a5bf-d8fa4d0874e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_5 = \"Search for 'Who are some witnesses for the Ms. Patel's accident and how can we contact them?' in the above defined index?\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb63877-6958-4a6f-a56b-631c8dedfed4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_6 = \"Search for 'Did Ms. Johnson sustain any injuries? If so, what were those injuries?' in the above defined index?\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c0d5bc0-bf0a-4655-b134-36ca028aa4a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message_7 = \"Search for 'Given the accident that happened on Lombard Street, name a party that is liable for the damages and explain why.' in the above defined index?\"\n",
    "\n",
    "agent_response = await user_proxy.a_initiate_chat(recipient=ai_search_agent, message=message_7)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "azdocintel-auto-insurance-rag-page-based chunking",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
