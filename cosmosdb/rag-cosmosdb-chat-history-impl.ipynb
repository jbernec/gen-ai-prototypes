{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca605898-ef54-4c99-996a-b72c362742bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Permission is based on File or folder based ACL assignments to the Data Lake filesystem (container) . RBAC assignments to the top level Azure Data Lake resource is not required.\n",
    "# https://docs.databricks.com/storage/azure-storage.html\n",
    "spark.conf.set(\"fs.azure.account.auth.type.adls04.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.adls04.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.adls04.dfs.core.windows.net\", dbutils.secrets.get(\"myscope\", key=\"clientid\"))\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.adls04.dfs.core.windows.net\", dbutils.secrets.get(\"myscope\", key=\"clientsecret\"))\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.adls04.dfs.core.windows.net\", \"https://login.microsoftonline.com/{}/oauth2/token\".format(dbutils.secrets.get(\"myscope\", key=\"tenantid\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d88b7b1-cc16-4828-9e3a-631815a07ed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "from azure.cosmos.aio import CosmosClient\n",
    "from azure.cosmos import  PartitionKey, exceptions\n",
    "from openai import AzureOpenAI\n",
    "from time import sleep\n",
    "import time\n",
    "import json\n",
    "import pyspark.pandas as ps\n",
    "import uuid\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c05b8af9-acb6-4b56-b363-fc0e2cf02d4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cosmosdb_url =dbutils.secrets.get(scope=\"myscope\", key=\"cosmosdb-url\")\n",
    "cosmosdb_key =dbutils.secrets.get(scope=\"myscope\", key=\"cosmosdb-key\")\n",
    "cosmosdb_database_name = dbutils.secrets.get(scope=\"myscope\", key=\"cosmosdb-database\")\n",
    "cosmosdb_collection_name = \"movies\"\n",
    "cosmos_vector_property_name = \"vector\"\n",
    "cosmosdb_chathistory_cache_name = \"chat_cache\"\n",
    "\n",
    "azure_openai_endpoint=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\")\n",
    "azure_openai_api_key=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\")\n",
    "azure_openai_deployment=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-deploymentname\")\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "azure_openai_embedding_deployment = dbutils.secrets.get(scope=\"myscope\", key=\"aoai-embedding-deployment\")\n",
    "azure_openai_embedding_model = dbutils.secrets.get(scope=\"myscope\", key=\"aoai-embedding-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05bcadec-9737-4369-8e91-1c9418d21284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cosmos_client = CosmosClient(url=cosmosdb_url, credential=cosmosdb_key)\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    api_key=azure_openai_api_key,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2c31e83-a32c-472c-bd22-01e3bc129d37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Create a database and containers with vector policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7bf76d9-88dd-495e-aefa-7509437ff95b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a database\n",
    "db = await cosmos_client.create_database_if_not_exists(id=cosmosdb_database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aff44aa2-af1a-4b1d-8253-dcfd198dc31b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the vector embedding policy\n",
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\": \"/\" + cosmos_vector_property_name,\n",
    "            \"dataType\": \"float32\",\n",
    "            \"distanceFunction\": \"dotproduct\",\n",
    "            \"dimensions\": 1536\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Create the vector index policy\n",
    "indexing_policy = {\n",
    "    \"includedPaths\": [{\"path\": \"/*\"}],\n",
    "    \"excludedPaths\": [\n",
    "        {\"path\": '/\"_etag\"/?', \"path\": \"/\" + cosmos_vector_property_name + \"/*\"}\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/\" + cosmos_vector_property_name, \"type\": \"quantizedFlat\"}\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "061f6bb8-a7bb-4ed7-8af4-11a606cb62d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the collection using the vector index policies\n",
    "try:\n",
    "    pass\n",
    "    container = await db.create_container_if_not_exists(\n",
    "        id=cosmosdb_collection_name,\n",
    "        partition_key=PartitionKey(path=\"/id\"),\n",
    "        vector_embedding_policy=vector_embedding_policy\n",
    "    )\n",
    "    print('Container with id \\'{0}\\' created'.format(id))\n",
    "except exceptions.CosmosHttpResponseError:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4944f192-5f2e-4a39-b5da-dc5c8129c491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the cache collection for storing chat history using the vector index policies\n",
    "try:\n",
    "    pass\n",
    "    container_cache = await db.create_container_if_not_exists(\n",
    "        id=cosmosdb_chathistory_cache_name,\n",
    "        partition_key=PartitionKey(path=\"/id\"),\n",
    "        vector_embedding_policy=indexing_policy\n",
    "    )\n",
    "    print('Container with id \\'{0}\\' created'.format(id))\n",
    "except exceptions.CosmosHttpResponseError:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96571f71-eb97-4357-925d-be4f16a2b5d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# develop function to embed movie data attributes.\n",
    "# add retry logic to handle throttling due to quota limits.\n",
    "\n",
    "\n",
    "# @retry(wait=wait_random_exponential(min=1, max=10))\n",
    "def generate_embeddings(text: str):\n",
    "    \"\"\"\n",
    "    Generate embeddings from string of text.\n",
    "    This will be used to vectorize data and user input for interactions with Azure OpenAI.\n",
    "    \"\"\"\n",
    "    response = azure_openai_client.embeddings.create(\n",
    "        input=text, model=azure_openai_embedding_deployment\n",
    "    )\n",
    "    embeddings = response.model_dump()\n",
    "    return embeddings[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5eb56aa-c14a-4708-be79-3eb503246cb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Load data and upload to azure cosmos db container\n",
    "####Azure Cosmos DB Python SDK does not currently support bulk inserts so we'll have to insert the items sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1201cb75-9096-4d57-b2fc-ab02366c1573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def upload_data_to_cosmosdb():\n",
    "    pass\n",
    "\n",
    "    json_data = \"abfss://experiments@adls04.dfs.core.windows.net/jsondata/cosmosdb-rag/\"\n",
    "    df_ = spark.read.format(\"json\").option(\"multiline\", \"true\").load(json_data)\n",
    "    #df_.display()\n",
    "    df_.count()\n",
    "\n",
    "    # Convert to pandas\n",
    "    df_pandas = ps.DataFrame(df_)\n",
    "    # Drop the 'vector' column from the pyspark.pandas DataFrame\n",
    "    df_pandas_ = df_pandas.drop(columns=['vector'])\n",
    "\n",
    "    # Capture just 5 records from the pyspark.pandas DataFrame\n",
    "    # df_pandas_head = df_pandas_.head(150)\n",
    "    df_pandas_head = df_pandas_\n",
    "\n",
    "    # Convert the captured records to JSON\n",
    "    json_records = df_pandas_head.to_json(orient='records')\n",
    "\n",
    "    # Convert JSON string to JSON object\n",
    "    json_object = json.loads(json_records)\n",
    "\n",
    "    # Generate embeddings for title and content fields and upload to cosmos db collection/container\n",
    "    n = 0\n",
    "    for item in json_object:\n",
    "        n+=1\n",
    "        id = item['id']\n",
    "        overview = item[\"overview\"]\n",
    "        tagline = item[\"tagline\"]\n",
    "        title = item[\"title\"]\n",
    "        overview_embeddings = generate_embeddings(overview)\n",
    "        item[\"vector\"] = overview_embeddings\n",
    "        item[\"@search.action\"] = \"upload\"\n",
    "        #print(\"Creating embeddings for item:\", n, \"/\" ,len(json_object), end='\\r')\n",
    "        #print(\".....uploading documents\")\n",
    "        await container.upsert_item(body=item)\n",
    "    print(\"Inserted {} documents into collection.\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15aa33e1-e380-4e29-a114-ebe486116b63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run function\n",
    "json_data = \"abfss://experiments@adls04.dfs.core.windows.net/jsondata/cosmosdb-rag/\"\n",
    "df_ = spark.read.format(\"json\").option(\"multiline\", \"true\").load(json_data)\n",
    "if df_.count() > 4489:\n",
    "    pass\n",
    "    await upload_data_to_cosmosdb()\n",
    "else:\n",
    "    print(\"The number of records is less than or equal to 4489. The function will not run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beb2cd2c-07ab-437d-a475-0bd77b97f09e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Vector search in Azure Cosmos DB for NoSQL\n",
    "#### Simple a function that will take in user's query, generate embeddings for the query text and then use the embedding to run a vector search to find the similar items. The most similar items must be used as additional knowledgebase for the completions model to answer the user's query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad6945c8-4dfa-4452-b0d3-138cab9da4ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-python-vector-index-query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17808dc2-ceef-4100-99a9-46cac7664803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Search retrieval function\n",
    "async def vector_search(query, container, similarity_score=0.03, num_results=2):\n",
    "    query_embedding = generate_embeddings(query)\n",
    "    search_result = \"\"\n",
    "    results = container.query_items(\n",
    "            query='SELECT TOP @num_results c.overview, c.title, VectorDistance(c.vector,@embedding) AS SimilarityScore  FROM c WHERE VectorDistance(c.vector,@embedding) > @similarity_score ORDER BY VectorDistance(c.vector,@embedding)',\n",
    "            parameters=[\n",
    "                {\"name\": \"@embedding\", \"value\": query_embedding}, \n",
    "                {\"name\": \"@num_results\", \"value\": num_results},\n",
    "                {\"name\": \"@similarity_score\", \"value\": similarity_score} \n",
    "            ],\n",
    "            #enable_cross_partition_query=True\n",
    "            )\n",
    "    formatted_results = []\n",
    "    async for result in results: \n",
    "        score = result.pop(\"SimilarityScore\")\n",
    "        formatted_result = {\n",
    "            'SimilarityScore': score,\n",
    "            \"document\": result\n",
    "        }\n",
    "        formatted_results.append(formatted_result)\n",
    "\n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f844b7e5-0735-4b94-8cb1-3fdafcf9ce44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# test the search retrieval function\n",
    "\n",
    "query= \"do you have a fantasy movie?\"\n",
    "results = await vector_search(query=query, container=container, num_results=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a5e21b9-6392-467b-8bb1-bff058452587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def get_chat_history(container_cache, completions=1):\n",
    "    results = container_cache.query_items(\n",
    "        query= '''\n",
    "        SELECT TOP @completions *\n",
    "        FROM c\n",
    "        ORDER BY c._ts DESC\n",
    "        ''',\n",
    "        parameters=[\n",
    "            {\"name\": \"@completions\", \"value\": completions},\n",
    "        ])\n",
    "    items = []\n",
    "    async for result in results:\n",
    "        items.append(result)\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ce482e-c6c9-4fb4-944b-8612eb92f799",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  pass\n",
    "  chat_hist = await get_chat_history(container_cache=container_cache)\n",
    "  print(chat_hist[0][\"completion\"])\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b623dbc6-58b2-40f8-9f12-a2df339c15b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#This function grounds the model with system prompts, user queries and vector search results to enable accurate and relevant responses.\n",
    "\n",
    "def generate_completion(vector_search_results, user_input, chat_history_list):\n",
    "    system_prompt = '''\n",
    "    You are an intelligent assistant for imdb movies.\n",
    "    You are designed to provide helpful answers to user questions about movies given the information about provided.\n",
    "        - Only answer questions related to the information provided below in the context.\n",
    "        - Write the response as key value pairs.\n",
    "        Example:\n",
    "            Title: Matrix\n",
    "            Overview: A movie about a man who is awoken from his sleep and finds himself in a strange new\n",
    "        - If you're unsure of an answer, you can say \"\"I don't know\"\" or \"\"I'm not sure\"\" and recommend users search themselves.\"\n",
    "        - Only provide answers that have movie titles and overview that are part of the provided context.\n",
    "    '''\n",
    "    # add system prompt\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    #chat history\n",
    "    for chat in chat_history_list:\n",
    "        messages.append({'role': 'user', 'content': chat['prompt'] + \" \" + chat['completion']})\n",
    "    #print(\"Temp Chat history Messages going to openai:\\n\", messages)\n",
    "    # add current user_input\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    for item in vector_search_results:\n",
    "        messages.append({\"role\": \"system\", \"content\": json.dumps(item[\"document\"])})\n",
    "        #print(\"####\")\n",
    "    #print(\"Vector search Messages going to openai:\\n\", messages)\n",
    "    response = azure_openai_client.chat.completions.create(model=azure_openai_deployment, messages=messages,temperature=0.1)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d9db4c8-3081-48b1-b009-d057766a9ae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# test the model generation function\n",
    "\n",
    "question = \"do you have a batman movie?\"\n",
    "#user_input = \"tell me about a tom cruise movie?\"\n",
    "search_results = await vector_search(query=question, container=container, similarity_score=0.03, num_results=2)\n",
    "x = generate_completion(vector_search_results=search_results, user_input=question, chat_history_list=await get_chat_history(container_cache=container_cache, completions=1))\n",
    "\n",
    "# x\n",
    "# print(\"\\n\\n\")\n",
    "x.to_dict()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b3cd65c-57ed-4f98-a9ed-d7b4f8bbb762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "search_results[0][\"document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9990daa-7f8f-4eaf-b5c6-d184c6b49743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def save_chat_history(container_cache, user_input, user_input_embedding, completion_results):\n",
    "    chat_history_object = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"prompt\": user_input,\n",
    "        \"completion\": completion_results.to_dict()[\"choices\"][0][\"message\"][\"content\"],\n",
    "        \"completionTokens\": str(completion_results.to_dict()[\"usage\"][\"completion_tokens\"]),\n",
    "        'promptTokens': str(completion_results.to_dict()['usage']['prompt_tokens']),\n",
    "        'totalTokens': str(completion_results.to_dict()['usage']['total_tokens']),\n",
    "        'model': completion_results.to_dict()['model'],\n",
    "        'vector': user_input_embedding\n",
    "        }\n",
    "    try:\n",
    "        pass\n",
    "        # Insert the chat document into the Cosmos DB container\n",
    "        await container_cache.create_item(body=chat_history_object)\n",
    "        #print(\"item inserted into cache.\", chat_history_object)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# Get chat history from chat history container\n",
    "# Perform a vector search on the Cosmos DB chat history container\n",
    "async def get_cache(container, vectors, similarity_score=0.02, num_results=1):\n",
    "    # Execute the query\n",
    "    formatted_results = []\n",
    "    results = container.query_items(\n",
    "        query= '''\n",
    "        SELECT TOP @num_results *\n",
    "        FROM c\n",
    "        WHERE VectorDistance(c.vector,@embedding) > @similarity_score\n",
    "        ORDER BY VectorDistance(c.vector,@embedding)\n",
    "        ''',\n",
    "        parameters=[\n",
    "            {\"name\": \"@embedding\", \"value\": vectors},\n",
    "            {\"name\": \"@num_results\", \"value\": num_results},\n",
    "            {\"name\": \"@similarity_score\", \"value\": similarity_score},\n",
    "        ], populate_query_metrics=True)\n",
    "    #results = list(results)\n",
    "    #print(results)\n",
    "    async for result in results: \n",
    "        #print(f\"Similarity Score: {result['SimilarityScore']}\") \n",
    "        formatted_results.append(result['completion'])\n",
    "\n",
    "    return formatted_results\n",
    "\n",
    "# Test the get chat history function\n",
    "await get_cache(container=container_cache, vectors=generate_embeddings(text=\"do you have a spy movie?\"), similarity_score=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f190a7d-6be9-4a59-a167-dc3f334eec4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Loop function to perform Q&A over the sample movie data! It uses the user input, search result to generate the model output.\n",
    "\n",
    "#### Also, add a chat history cache container/collection to the cosmos db database. This will first be checked before routing queries to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c50ad66f-2650-4f50-a06b-69d06b86a6fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a loop of user input and model output. You can now perform Q&A over the sample data!# Create a loop of user input and model output. You can now perform Q&A over the sample data!\n",
    "\n",
    "async def chat_loop():\n",
    "    pass\n",
    "    print(\"*** Please ask your model questions about imdb movies. Type 'end' to end the session.\")\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"User prompt: \").lower()\n",
    "            user_input_embeddings = generate_embeddings(text=user_input)\n",
    "            \n",
    "            # Query the chat history cache first to see if this question has been asked before\n",
    "            cache_results = await get_cache(container=container_cache, vectors=user_input_embeddings, similarity_score=0.02, num_results=1)\n",
    "            if len(cache_results) > 0:\n",
    "                pass\n",
    "                print(\"Cached Result\\n\")\n",
    "                print(cache_results[0])\n",
    "                continue\n",
    "                \n",
    "            if user_input == \"end\":\n",
    "                print(\"\\n\\nExiting chat..\")\n",
    "                print(\"Good bye, please let me know if you need further help.\")\n",
    "                break\n",
    "                \n",
    "                #return \"Good bye, please let me know if you need further help.\"\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        search_results = await vector_search(query=user_input, container=container, similarity_score=0.03, num_results=2)\n",
    "        #chat history\n",
    "        chat_history_list = await get_chat_history(container_cache=container_cache, completions=1)\n",
    "        completion_results = generate_completion(vector_search_results=search_results, user_input=user_input, chat_history_list=chat_history_list)\n",
    "        print(\"Completion Result\\n\")\n",
    "        \n",
    "        # save the chat history to cosmos db\n",
    "        await save_chat_history(container_cache=container_cache, user_input=user_input, user_input_embedding=user_input_embeddings, completion_results=completion_results)\n",
    "        #return completion_results.to_dict()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(completion_results.to_dict()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cddbf188-905c-4b2d-a6ee-f81f55518426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run the function\n",
    "await chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef2e18ed-72e2-480d-a013-e47afcb93115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create a Gradio UI for the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b967b664-10b4-4e9e-8b2e-0361dd23ef8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a loop of user input and model output. You can now perform Q&A over the sample data!\n",
    "\n",
    "async def chat_bot_function(user_input):\n",
    "    \n",
    "    #print(\"*** Please ask your model questions about imdb movies. Type 'end' to end the session.\")\n",
    "    try:\n",
    "        user_input = user_input.lower()\n",
    "        # Query the chat history cache first to see if this question has been asked before\n",
    "        user_input_embeddings = generate_embeddings(text=user_input)\n",
    "        cache_results = await get_cache(container=container_cache, vectors=user_input_embeddings, similarity_score=0.99, num_results=1)\n",
    "        if len(cache_results) > 0:\n",
    "            print(\"Cached Result\\n\")\n",
    "            return cache_results[0]\n",
    "\n",
    "        search_results = await vector_search(query=user_input, container=container, similarity_score=0.8, num_results=1)\n",
    "        chat_history_list = await get_chat_history(container_cache=container_cache, completions=1)\n",
    "        completion_results = generate_completion(vector_search_results=search_results, user_input=user_input, chat_history_list=chat_history_list)\n",
    "        await save_chat_history(container_cache=container_cache, user_input=user_input, user_input_embedding=user_input_embeddings, completion_results=completion_results)\n",
    "        response = completion_results.to_dict()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(\"Completion Result\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02647d9e-bc62-4db7-97b5-7b688cc7b588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"do you have a spy movie?\"\n",
    "await chat_bot_function(user_input=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a17569b4-d67e-46d5-8bd4-364caf31375a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_response(message, history):\n",
    "    formatted_history = []\n",
    "    for user, assistant in history:\n",
    "        formatted_history.append({\"role\": \"user\", \"content\": user })\n",
    "        formatted_history.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "\n",
    "    formatted_history.append({\"role\": \"user\", \"content\": message})\n",
    "  \n",
    "    response = client.chat.completions.create(model='gpt-3.5-turbo',\n",
    "    messages= formatted_history,\n",
    "    temperature=1.0)\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0432256-c7ed-4b05-a472-14cce72a00aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gr.ChatInterface(\n",
    "    fn=chat_bot_function,\n",
    "    chatbot=gr.Chatbot(label=\"Assistant\", height=250),\n",
    "    textbox=gr.Textbox(placeholder=\"Ask me a question about any movie\", scale=7),\n",
    "    title=\"RAG Movie Recommender\",\n",
    "    #description=\"I will try to answer your movie related questions as accurately as possible\",\n",
    "    theme=\"soft\",\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    ").launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rag-cosmosdb-chat-history-impl",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
