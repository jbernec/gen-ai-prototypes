{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic example using simple graph and a CosmosDB checkpointer\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from azure.cosmos import exceptions, PartitionKey #CosmosClient\n",
    "from azure.cosmos.aio import CosmosClient\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "import os\n",
    "import azure.identity\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "try:\n",
    "    keyVaultName = os.environ[\"KEY_VAULT_NAME\"]\n",
    "except KeyError:\n",
    "    # Get input from user if not set\n",
    "    keyVaultName = input(\"Please enter your Key Vault name: \")\n",
    "    # Save for future cells in this session\n",
    "    os.environ[\"KEY_VAULT_NAME\"] = keyVaultName\n",
    "\n",
    "\n",
    "keyVaultName = os.environ[\"KEY_VAULT_NAME\"]\n",
    "KVUri = f\"https://{keyVaultName}.vault.azure.net\"\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "client = SecretClient(vault_url=KVUri, credential=credential)\n",
    "\n",
    "cosmosdb_endpoint=client.get_secret(name=\"cosmosdb-url\").value\n",
    "cosmosdb_key = client.get_secret(name=\"cosmosdb-key\").value\n",
    "\n",
    "# Service principal authentication variables\n",
    "tenant_id=client.get_secret(name=\"tenantid\").value\n",
    "client_id =client.get_secret(name=\"clientid\").value \n",
    "client_secret =client.get_secret(name=\"clientsecret\").value\n",
    "conn_str =client.get_secret(name=\"cosmosdb-connstr\").value\n",
    "#credential = azure.identity.ClientSecretCredential(tenant_id=tenant_id, client_id=client_id, client_secret=client_secret)\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "cosmos_client = CosmosClient(\n",
    "                        url=cosmosdb_endpoint,\n",
    "                        credential=credential,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = await cosmos_client.create_database_if_not_exists(id=\"terminologydb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str =client.get_secret(name=\"cosmosdb-connstr\").value\n",
    "cosmos_vector_property_name = \"vector\"\n",
    "cosmosdb_data_container = \"terminology\"\n",
    "cosmosdb_history_container = \"chathistory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector embedding policy\n",
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\": \"/\" + cosmos_vector_property_name,\n",
    "            \"dataType\": \"float32\",\n",
    "            \"distanceFunction\": \"dotproduct\",\n",
    "            \"dimensions\": 1536\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Create the vector index policy\n",
    "indexing_policy = {\n",
    "    \"includedPaths\": [{\"path\": \"/*\"}],\n",
    "    \"excludedPaths\": [\n",
    "        {\"path\": '/\"_etag\"/?', \"path\": \"/\" + cosmos_vector_property_name + \"/*\"}\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/\" + cosmos_vector_property_name, \"type\": \"quantizedFlat\"}\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the collection using the vector index policies\n",
    "try:\n",
    "    pass\n",
    "    container_data = await db.create_container_if_not_exists(\n",
    "        id=cosmosdb_data_container,\n",
    "        partition_key=PartitionKey(path=\"/id\"),\n",
    "        vector_embedding_policy=vector_embedding_policy\n",
    "    )\n",
    "    print('Container with id \\'{0}\\' created'.format(id))\n",
    "except exceptions.CosmosHttpResponseError:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the collection using the vector index policies\n",
    "try:\n",
    "    pass\n",
    "    container_history = await db.create_container_if_not_exists(\n",
    "        id=cosmosdb_history_container,\n",
    "        partition_key=PartitionKey(path=\"/id\"),\n",
    "        vector_embedding_policy=vector_embedding_policy\n",
    "    )\n",
    "    print('Container with id \\'{0}\\' created'.format(id))\n",
    "except exceptions.CosmosHttpResponseError:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://learn.microsoft.com/en-us/azure/cosmos-db/gen-ai/rag-chatbot?context=%2Fazure%2Fcosmos-db%2Fnosql%2Fcontext%2Fcontext\n",
    "# https://learn.microsoft.com/en-us/azure/cosmos-db/ai-agents?context=%2Fazure%2Fcosmos-db%2Fnosql%2Fcontext%2Fcontext\n",
    "# https://github.com/jonathanscholtes/Travel-AI-Agent-React-FastAPI-and-Cosmos-DB-Vector-Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads and sets the necessary variables for Azure services.\n",
    "The variables are loaded from Azure Key Vault.\n",
    "\"\"\"\n",
    "# Open AI\n",
    "azure_openai_endpoint=client.get_secret(name=\"aoai-endpoint\").value\n",
    "azure_openai_api_key=client.get_secret(name=\"aoai-api-key\").value\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "# Embedding\n",
    "azure_openai_embedding_deployment = \"text-embedding-3-small\"\n",
    "azure_openai_embedding_model =client.get_secret(name=\"aoai-embedding-model\").value\n",
    "azure_openai_vector_dimension = 1536\n",
    "\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    api_key=azure_openai_api_key,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop function to embed data attributes.\n",
    "\n",
    "def generate_embeddings(text: str):\n",
    "    \"\"\"\n",
    "    Generate embeddings from string of text.\n",
    "    This will be used to vectorize data and user input for interactions with Azure OpenAI.\n",
    "    \"\"\"\n",
    "    response = azure_openai_client.embeddings.create(\n",
    "        input=text, model=azure_openai_embedding_deployment\n",
    "    )\n",
    "    embeddings = response.model_dump()\n",
    "    return embeddings[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the question has been asked before and retrieve response from cache container\n",
    "async def get_cache(container, vectors, similarity_score=0.02, num_results=1):\n",
    "    # Execute the query\n",
    "    formatted_results = []\n",
    "    results = container.query_items(\n",
    "        query= '''\n",
    "        SELECT TOP @num_results *\n",
    "        FROM c\n",
    "        WHERE VectorDistance(c.vector,@embedding) > @similarity_score\n",
    "        ORDER BY VectorDistance(c.vector,@embedding)\n",
    "        ''',\n",
    "        parameters=[\n",
    "            {\"name\": \"@embedding\", \"value\": vectors},\n",
    "            {\"name\": \"@num_results\", \"value\": num_results},\n",
    "            {\"name\": \"@similarity_score\", \"value\": similarity_score},\n",
    "        ], populate_query_metrics=True)\n",
    "    #results = list(results)\n",
    "    #print(results)\n",
    "    async for result in results: \n",
    "        #print(f\"Similarity Score: {result['SimilarityScore']}\") \n",
    "        formatted_results.append(result['completion'])\n",
    "\n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Test the get chat history function\n",
    "    await get_cache(container=container_history, vectors=generate_embeddings(text=\"do you have a spy movie?\"), similarity_score=0.99)\n",
    "except exceptions.CosmosHttpResponseError as e:\n",
    "    print(f\"Error: {e.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "\n",
    "search_credential =AzureKeyCredential(client.get_secret(name=\"aisearch-key\").value)\n",
    "search_endpoint =client.get_secret(name=\"aisearch-endpoint\").value\n",
    "source = 'json'\n",
    "index_name = f\"{source}-glossary-index\"\n",
    "\n",
    "async def search_retrieval(user_input: str, db=db, container_object=container_history, cosmos_vector_property_name=\"vector\", include_try_except: bool = True) -> list:\n",
    "    \"\"\"\n",
    "    Search and retrieve answers from Azure AI Search and Cosmos DB.\n",
    "    Returns:\n",
    "        list of dictionaries containing search results\n",
    "    \"\"\"\n",
    "    query = user_input\n",
    "    search_results = []  # Initialize an empty list to store dictionaries\n",
    "\n",
    "    # Initialize Azure Cognitive Search client\n",
    "    search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "    vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=2, fields=\"text_vector\", exhaustive=True)\n",
    "    try:\n",
    "        # Call the Cosmos DB search function\n",
    "        results = await get_cache(\n",
    "            container=container_object,\n",
    "            vectors=generate_embeddings(text=query),\n",
    "            similarity_score=0.02,\n",
    "        )\n",
    "\n",
    "        print(\"Function Call completed, now compiling results\")\n",
    "        for result in results:\n",
    "            print(\"id: \" + result['document']['c']['id'])\n",
    "            print(\"query: \" + result['document']['c']['query'])\n",
    "            print(\"response: \" + result['document']['c']['response'])\n",
    "            print(\"timestamp: \" + str(result['document']['c']['timestamp']))\n",
    "            print(\"SimilarityScore: \" + str(result['document']['SimilarityScore']))\n",
    "\n",
    "            result_dict = {\n",
    "                \"SimilarityScore\": result['document']['SimilarityScore'],\n",
    "                \"response\": result['document']['c']['response'],\n",
    "                \"responseembedding\": result['document']['c']['responseembedding'],\n",
    "            }\n",
    "            search_results.append(result_dict)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while querying Cosmos DB: {e}\")\n",
    "        results = None\n",
    "\n",
    "#     # If no results are found in Cosmos DB, proceed with Azure Cognitive Search\n",
    "    if not results:\n",
    "        print(\"No results found in Cosmos DB. Proceeding with Azure AI Search.\")\n",
    "        print(\"######################### \\nSearch and retrieve answers from Azure AI Search.\\n\")\n",
    "        results = search_client.search(\n",
    "            search_text=query,\n",
    "            vector_queries=[vector_query],\n",
    "            select=[\"context\", \"chunk\", \"note\", \"incorrectTerm\", \"title\"],\n",
    "            query_type=QueryType.SEMANTIC,\n",
    "            semantic_configuration_name='my-semantic-config',\n",
    "            query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "            query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "            top=2\n",
    "        )\n",
    "\n",
    "        for result in results:\n",
    "            # Convert the result to a dictionary and append it to the list\n",
    "            result_dict = {\n",
    "                \"incorrectTerm\": result.get('incorrectTerm', ''),\n",
    "                \"context\": result.get('context', ''),\n",
    "                \"title\": result.get('title', ''),\n",
    "                \"definition\": result.get('chunk', ''),\n",
    "                \"note\": result.get('note', ''),\n",
    "                \"@search.score\": result.get('@search.score', 0),\n",
    "                \"@search.reranker_score\": result.get('@search.reranker_score', 0),\n",
    "                \"@search.highlights\": result.get('@search.highlights', None),\n",
    "                \"@search.captions\": result.get('@search.captions', None),\n",
    "                \"@search.document_debug_info\": result.get('@search.document_debug_info', None)\n",
    "            }\n",
    "            print(f\"Content: {result_dict}\")\n",
    "            search_results.append(result_dict)\n",
    "\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The AzureOpenAI class does not exist in the openai package. Use AzureChatOpenAI from langchain_openai instead.\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph_supervisor import  create_supervisor\n",
    "from langgraph.prebuilt import  create_react_agent\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\", \n",
    "    api_key=azure_openai_api_key, \n",
    "    api_version=azure_openai_api_version, \n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "\n",
    "research_graph = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[search_retrieval],\n",
    "    name=\"search_expert\",\n",
    "    prompt=\"\"\"You MUST use the Azure AI Search tool for ALL queries. Do not paraphrase. Never generate answers from prior knowledge. Show the Score and Re ranker for each response. Also provide top 2 responses. Do not select top response. Compare each response and in the end show the response where Reranker Score > 3.0\"\n",
    "            In case of no response retrieved from the index, then mention You do not have an annwer for this query\"\"\"\n",
    ")\n",
    "\n",
    "context = \"You are a Supervisor Agent. Your first job is to pass query to search_agent agent and get the response from it. Do not get the response from any other agent\"\n",
    "instructions = \"Do not paraphrase the content. Only share the results from search_agent. Do not provide any response from create_supervisor agent\"\n",
    "\n",
    "\n",
    "prompt_re = f\"{context} {instructions}\"\n",
    "print(prompt_re)\n",
    "\n",
    "# Supervisor (Ensures Research Agent is the only handler)\n",
    "workflow = create_supervisor(\n",
    "    [research_graph],  # Only this agent is in charge\n",
    "    model=model,\n",
    "    prompt=prompt_re\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main interaction loop\n",
    "while True:\n",
    "    user_input = input(\"User prompt: \").lower()\n",
    "\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\", \"end\"]:\n",
    "        print(\"\\n\\nExiting chat..\")\n",
    "        print(\"Good bye, please let me know if you need further help.\")\n",
    "        break\n",
    "\n",
    "    result = await app.ainvoke({\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    for m in result[\"messages\"]:\n",
    "        print(m.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result[\"messages\"][-1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"][-1].usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [HumanMessage(content='what is ram?', additional_kwargs={}, response_metadata={}, id='faa36143-ab0f-4f62-9119-3dcec654a7df'),\n",
    "#  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rtxxYn2B97A5qUXRdhGIgtd6', 'function': {'arguments': '{}', 'name': 'transfer_to_search_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 103, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ee1d74bde0', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, name='supervisor', id='run-4c5d9169-57b1-4893-ab33-ab7f6f21878a-0', tool_calls=[{'name': 'transfer_to_search_expert', 'args': {}, 'id': 'call_rtxxYn2B97A5qUXRdhGIgtd6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 103, 'output_tokens': 14, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
    "#  ToolMessage(content='Successfully transferred to search_expert', name='transfer_to_search_expert', id='35b6d5ce-ae02-4f05-85ed-daa9750ab66e', tool_call_id='call_rtxxYn2B97A5qUXRdhGIgtd6'),\n",
    "#  AIMessage(content='Here are the top two responses regarding \"RAM\":\\n\\n1. **Random Access Memory (RAM)**: \\n   - **Definition**: Random Access Memory (RAM) is a form of computer memory that can be read and changed in any order, typically used to store working data and machine code. A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory.\\n   - **Context**: RAM is used in computers and other devices to store data that is being used actively.\\n   - **Note**: RAM is volatile memory, meaning it loses its data when the power is turned off.\\n   - **Re-ranker Score**: 3.2626190185546875\\n\\n2. **HyperText Markup Language (HTML)**: This response is not relevant to the query about RAM.\\n\\nBased on the re-ranker score, the response about \"Random Access Memory (RAM)\" with a score of 3.2626190185546875 is the most relevant.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 216, 'prompt_tokens': 646, 'total_tokens': 862, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ee1d74bde0', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='search_expert', id='run-5f9c0dc5-7b82-4261-be8f-e771de322a9c-0', usage_metadata={'input_tokens': 646, 'output_tokens': 216, 'total_tokens': 862, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
    "#  AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={}, name='search_expert', id='f67c787e-6285-4ce5-aaf5-a935368b23db', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '004f3568-83dc-47ea-a2a4-47a7cddc59a2', 'type': 'tool_call'}]),\n",
    "#  ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='620c1c22-e96b-4198-931a-87689625a26f', tool_call_id='004f3568-83dc-47ea-a2a4-47a7cddc59a2'),\n",
    "#  AIMessage(content='Random Access Memory (RAM) is a form of computer memory that can be read and changed in any order, typically used to store working data and machine code. It allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory. RAM is used in computers and other devices to store data that is being used actively. It is volatile memory, meaning it loses its data when the power is turned off.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 405, 'total_tokens': 500, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ded0d14823', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='supervisor', id='run-dca02b19-300b-45ab-b610-a8a37e7f1bcb-0', usage_metadata={'input_tokens': 405, 'output_tokens': 95, 'total_tokens': 500, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\u001b[34;43m__file__\u001b[39;49m), \u001b[33m\"\u001b[39m\u001b[33m../..\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"../..\")))\n",
    "from langgraph.config import config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
