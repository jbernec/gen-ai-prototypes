{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36bb9bfe-65b0-49ae-bff9-f8f2a45ec9bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### In this notebook I demonstrate the use of the Azure AI Search Integrated Vectorization feature. and the Split Skill and Azure Open AI Embedding skill to index and build an agentic RAG solution on a glossary dataset in the CSV file format.\n",
    "* Key vault retrievals are implemented using the azure key vault sdk\n",
    "* The data source object connection string parameter was updated to use the storage account resource id: ResourceId=/subscriptions/00000000-0000-8888-7777-555555555555/resourceGroups/rgxxx/providers/Microsoft.Storage/storageAccounts/blob00000store\n",
    "* The NativeBlobSoftDeleteDeletionDetectionPolicy is not supported for parsingMode indexer config set to delimitedText. Further research required\n",
    "* It's important that the requirements.txt file pinned packages in this directory are used, to avoid breaking changes in newer versions for now\n",
    "* https://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-document-intelligence-layout\n",
    "* https://learn.microsoft.com/en-us/azure/search/search-how-to-semantic-chunking\n",
    "* SplitSkill to chunk the data\n",
    "* AzureOpenAIEmbedding skill to embed the dataset \"Definition\" field \n",
    "* Deploy the following services in the same region; Azure AI Document Intelligence, Azure AI Search, Azure Open AI, AI Foundry, Azure Blob Storage\n",
    "* Enable system assigned managed identity\n",
    "* Deploy text-embedding-3-small on Azure OpenAI (in Azure AI Foundry) for embeddings\n",
    "* Deploy gpt-4o on Azure OpenAI for chat completion\n",
    "* Configure search engine RBAC to Azure Blob Storage by adding a role for Storage Blob Data Reader, assigned to the search service system-managed identity\n",
    "* Configure search engine RBAC to Azure Open AI by adding a role for Cognitive Services OpenAI User, assigned to the search service system-managed identity\n",
    "* The model names and endpoint should be saved in AKV. Embedding skills and vectorizers assemble the full endpoint internally, so only the resource URI is needed. For example, given https://MY-FAKE-ACCOUNT.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-06-01, the endpoint should to be provided in skill and vectorizer definitions is https://MY-FAKE-ACCOUNT.openai.azure.com.\n",
    "* The Azure AI multiservice account is used for skills processing. The multiservice account key must be provided, even if RBAC is in use. The key isn't used on the connection, but it's currently used for billing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b49d8507-cef3-4dd7-a839-90785e45efef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install azure\n",
    "# %pip install azure-keyvault-secrets\n",
    "# %pip install azure-storage-blob\n",
    "# %pip install azure-identity azure-search-documents azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d7131c8-493d-4ec8-aa00-92245f8f6035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "import azure.identity\n",
    "from azure.identity import DefaultAzureCredential, EnvironmentCredential, ManagedIdentityCredential, SharedTokenCacheCredential\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, AnalyzeDocumentRequest\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex,\n",
    "    BlobIndexerParsingMode,\n",
    "    SemanticConfiguration, SemanticSearch, SemanticPrioritizedFields, SemanticField\n",
    ")\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "import os\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.identity import DefaultAzureCredential, AzureAuthorityHosts\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42ed4eaa-5b15-4477-bb61-d0ef8a804d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define Required Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     keyVaultName = os.environ[\"KEY_VAULT_NAME\"]\n",
    "# except KeyError:\n",
    "#     # Get input from user if not set\n",
    "#     keyVaultName = input(\"Please enter your Key Vault name: \")\n",
    "#     # Save for future cells in this session\n",
    "#     os.environ[\"KEY_VAULT_NAME\"] = keyVaultName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyVaultName = os.environ[\"KEY_VAULT_NAME\"]\n",
    "keyVaultName = \"akvlab00\"  # Replace with your Key Vault name\n",
    "KVUri = f\"https://{keyVaultName}.vault.azure.net\"\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "client = SecretClient(vault_url=KVUri, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a658011-70c3-4a56-a0cf-6aed3b154194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads and sets the necessary variables for Azure services.\n",
    "The variables are loaded from Azure Key Vault.\n",
    "\"\"\"\n",
    "# Open AI\n",
    "azure_openai_endpoint=client.get_secret(name=\"aoai-endpoint\").value\n",
    "azure_openai_api_key=client.get_secret(name=\"aoai-api-key\").value\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "# Embedding\n",
    "# azure_openai_embedding_deployment = client.get_secret(name=\"aoai-embedding-deployment\").value\n",
    "azure_openai_embedding_deployment = \"text-embedding-3-small\"\n",
    "azure_openai_embedding_model =client.get_secret(name=\"aoai-embedding-model\").value\n",
    "azure_openai_vector_dimension = 1536\n",
    "# AI Search\n",
    "search_credential =AzureKeyCredential(client.get_secret(name=\"aisearch-key\").value)\n",
    "search_endpoint =client.get_secret(name=\"aisearch-endpoint\").value\n",
    "source = 'json'\n",
    "index_name = f\"{source}-glossary-index\"\n",
    "# AI Service\n",
    "data_source_connection_name = f\"{source}-glossary-ds\"\n",
    "azure_ai_services_key =client.get_secret(name=\"azure-ai-services-key\").value\n",
    "azure_ai_services_endpoint =client.get_secret(name=\"azure-ai-services-endpoint\").value\n",
    "# Blob Storage\n",
    "blob_container_name = f\"{source}-data\"\n",
    "blob_storage_name =client.get_secret(name=\"blobstore-account-name\").value\n",
    "# Cognitive Services\n",
    "# azure_ai_cognitive_services_key = client.get_secret(name=\"azure-ai-cognitive-services-key\").value\n",
    "# azure_ai_cognitive_services_endpoint = client.get_secret(name=\"azure-ai-cognitive-services-endpoint\").value\n",
    "azure_ai_services_key =client.get_secret(name=\"azure-ai-services-key\").value\n",
    "azure_ai_services_endpoint =client.get_secret(name=\"azure-ai-services-endpoint\").value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865392b6-e124-4ac8-85d6-320c8489743a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Azure AI Search Datasource Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc31b92d-7ca5-475c-8544-5c8ceaaa224f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source json-glossary-ds created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataIdentity,\n",
    "    SearchIndexerDataUserAssignedIdentity,\n",
    "    SearchIndexerDataNoneIdentity\n",
    ")\n",
    "from azure.search.documents.indexes.models import (\n",
    "    NativeBlobSoftDeleteDeletionDetectionPolicy,\n",
    "    HighWaterMarkChangeDetectionPolicy,\n",
    "    DataChangeDetectionPolicy\n",
    ")\n",
    "\n",
    "indexer_client = SearchIndexerClient(\n",
    "    endpoint=search_endpoint, credential=search_credential\n",
    ")\n",
    "indexer_container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "resource_id = client.get_secret(name=\"ds-resource-id\").value\n",
    "data_source_connection = SearchIndexerDataSourceConnection(name=data_source_connection_name, type=\"azureblob\", connection_string=resource_id, container=indexer_container)\n",
    "data_source_connection\n",
    "# Create the data source object\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection=data_source_connection)\n",
    "\n",
    "print(f\"Data source {data_source.name} created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dd4c984-9d0e-4c65-90b8-b830be4727e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Azure AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3bc09c0-3339-4c83-a38b-5719184a7093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fields = [\n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, searchable=True, filterable=False, sortable=True, key=True, facetable=False, analyzer_name=\"keyword\"),\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, searchable=False, filterable=True, sortable=False, key=False, facetable=False),\n",
    "     SearchField(name=\"chunk\", type=SearchFieldDataType.String, searchable=True, filterable=False, sortable=False, facetable=False, key=False),\n",
    "    SearchField(name=\"title\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"text_vector\",type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, filterable=False, sortable=False, facetable=False, key=False, vector_search_dimensions=azure_openai_vector_dimension, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"gender\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"definition\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"context\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"note\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"incorrectTerm\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"domain\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"modificationDate\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"source\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"link\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"englishTerm\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"creationDate\",type=SearchFieldDataType.String, searchable=True, sortable=True, filterable=True, facetable=True),\n",
    "]\n",
    "\n",
    "# Define the vector search configuration and parameters\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(name=\"myHsnw\")\n",
    "\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHsnw\",\n",
    "            vectorizer_name=\"myOpenAI\"\n",
    "        )\n",
    "    ],\n",
    "    vectorizers=[\n",
    "        AzureOpenAIVectorizer(\n",
    "            vectorizer_name=\"myOpenAI\",\n",
    "            kind=\"azureOpenAI\",\n",
    "            parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_embedding_deployment,\n",
    "                model_name=azure_openai_embedding_model,\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure semantic search on the index\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"chunk\"),\n",
    "        content_fields=[SemanticField(field_name=\"chunk\"), SemanticField(field_name=\"context\"), SemanticField(field_name=\"note\"), SemanticField(field_name=\"incorrectTerm\")],\n",
    "        keywords_fields=[SemanticField(field_name=\"chunk\"), SemanticField(field_name=\"context\"), SemanticField(field_name=\"note\"), SemanticField(field_name=\"incorrectTerm\")],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic search config\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "scoring_profiles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c35313-e690-40ca-ba9f-d25a4339737e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json-glossary-index created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index client required to create the index\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, scoring_profiles=scoring_profiles, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index=index)\n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e26ae82-b593-43c7-ab2d-2931bd7cd642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> #### Create Required Skillsets for the document extraction processes and operations.\n",
    "Skills drive integrated vectorization. Text Split provides data chunking. AzureOpenAIEmbedding handles calls to Azure OpenAI, using the connection information you provide in the environment variables. An indexer projection specifies secondary indexes used for chunked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    OcrSkill,\n",
    "    SearchIndexerSkillset,\n",
    "    DocumentIntelligenceLayoutSkill,\n",
    "    DocumentIntelligenceLayoutSkillMarkdownHeaderDepth,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    AIServicesAccountKey,\n",
    "    AIServicesAccountIdentity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created skillset json-glossary-index-skillset\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    OcrSkill,\n",
    "    SearchIndexerSkillset,\n",
    "    DocumentIntelligenceLayoutSkill,\n",
    "    DocumentIntelligenceLayoutSkillMarkdownHeaderDepth,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    AIServicesAccountKey,\n",
    "    AIServicesAccountIdentity\n",
    ")\n",
    "\n",
    "skillset_name = f\"{index_name}-skillset\"\n",
    "\n",
    "def create_skillset():\n",
    "    split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    default_language_code=\"en\",  \n",
    "    context=\"/document\",\n",
    "    maximum_page_length=2000,  \n",
    "    page_overlap_length=500,\n",
    "    maximum_pages_to_take=0,\n",
    "    unit = \"characters\",   \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/definition\"),\n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ]  \n",
    "    )  \n",
    "\n",
    "    embedding_skill = AzureOpenAIEmbeddingSkill(\n",
    "        description=\"Skill to generate embeddings via Azure OpenAI\",\n",
    "        context=\"/document/pages/*\",\n",
    "        resource_url=azure_openai_endpoint,\n",
    "        deployment_name=azure_openai_embedding_deployment,\n",
    "        model_name=azure_openai_embedding_model,\n",
    "        dimensions=azure_openai_vector_dimension,\n",
    "        api_key=azure_openai_api_key,\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"), # Chunking the definition\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\") # Inserting the chunks into text_vector of enriched doc\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    index_projections = SearchIndexerIndexProjection(\n",
    "        selectors=[\n",
    "            SearchIndexerIndexProjectionSelector(\n",
    "                target_index_name=index_name,\n",
    "                parent_key_field_name=\"parent_id\",\n",
    "                source_context=\"/document/pages/*\",\n",
    "                mappings=[\n",
    "                    InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "                    InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),\n",
    "                    InputFieldMappingEntry(name=\"title\", source=\"/document/title\"),\n",
    "                    InputFieldMappingEntry(name=\"gender\", source=\"/document/gender\"),\n",
    "                    InputFieldMappingEntry(name=\"definition\", source=\"/document/definition\"),\n",
    "                    InputFieldMappingEntry(name=\"incorrectTerm\", source=\"/document/incorrectTerm\"),\n",
    "                    InputFieldMappingEntry(name=\"domain\", source=\"/document/domain\"),\n",
    "                    InputFieldMappingEntry(name=\"englishTerm\", source=\"/document/englishTerm\"),\n",
    "                    InputFieldMappingEntry(name=\"creationDate\", source=\"/document/creationDate\"),\n",
    "                    InputFieldMappingEntry(name=\"modificationDate\", source=\"/document/modificationDate\"),\n",
    "                    InputFieldMappingEntry(name=\"source\", source=\"/document/source\"),\n",
    "                    InputFieldMappingEntry(name=\"link\", source=\"/document/link\"),\n",
    "                    InputFieldMappingEntry(name=\"context\", source=\"/document/context\"),\n",
    "                    InputFieldMappingEntry(name=\"note\", source=\"/document/note\"),\n",
    "\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        parameters=SearchIndexerIndexProjectionsParameters(\n",
    "            projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
    "        )\n",
    "    )\n",
    "\n",
    "    skills = [split_skill, embedding_skill]\n",
    "\n",
    "    return SearchIndexerSkillset(\n",
    "        name=skillset_name,\n",
    "        description=\"Skillset to chunk documents and generating embeddings\",\n",
    "        skills=skills,\n",
    "        index_projection=index_projections,\n",
    "        cognitive_services_account=AIServicesAccountKey(key=azure_ai_services_key, subdomain_url=azure_ai_services_endpoint)\n",
    "    )\n",
    "\n",
    "skillset = create_skillset()\n",
    "\n",
    "\n",
    "indexer_client.create_or_update_skillset(skillset)\n",
    "print(f\"Created skillset {skillset.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b4c4574-5ae6-4ad1-ad5f-d2a37a2cd69e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7008d8d8-dc12-4b0d-9a18-73f2020d38e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " json-glossary-index-indexer is created and running. If queries return no results, please wait a bit and try again.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    BlobIndexerImageAction\n",
    ")\n",
    "\n",
    "# Define indexer name  \n",
    "indexer_name = f\"{index_name}-indexer\"\n",
    "\n",
    "index_parameters = IndexingParameters(\n",
    "    configuration=IndexingParametersConfiguration(\n",
    "      data_to_extract=\"contentAndMetadata\", # contentAndMetadata\n",
    "      parsing_mode=\"jsonArray\", # jsonLines\n",
    "      document_root=\"terms/term\", #/document\n",
    "      # fail_on_unprocessable_document=False,\n",
    "      # fail_on_unsupported_content_type=False,\n",
    "      # first_line_contains_headers=True,\n",
    "      query_timeout=None,\n",
    "      # allow_skillset_to_read_file_data=True\n",
    "    )\n",
    "  )\n",
    "\n",
    "indexer = SearchIndexer(\n",
    "  name=indexer_name,\n",
    "  description=\"Indexer to orchestrate the document indexing and embedding generation\",\n",
    "  skillset_name=skillset_name,\n",
    "  target_index_name=index_name,\n",
    "  data_source_name=data_source.name\n",
    "  ,parameters=index_parameters\n",
    ")\n",
    "\n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)\n",
    "\n",
    "# Run the indexer to kick off the indexing process\n",
    "indexer_client.run_indexer(indexer_name)\n",
    "print(f' {indexer_name} is created and running. If queries return no results, please wait a bit and try again.')\n",
    "\n",
    "# Schedule an indexer to run every 24 hours\n",
    "#https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/search/azure-search-documents/samples/sample_indexer_datasource_skillset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c659d974-38e9-490e-b5cb-051039d2282f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Perform a vector similarity search\n",
    "\n",
    "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization.\n",
    "\n",
    "If you indexed the health plan PDF file, send queries that ask plan-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize Search - Searching algorithm/ Return multiple Scores/ values\n",
    "# Add Incorrect Term - Done\n",
    "# Language\n",
    "# Json or XML\n",
    "# Another alternate for Searching Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 8.409295\n",
      "Definition: Deoxyribonucleic acid (DNA) is a molecule composed of two polynucleotide chains that coil around each other to form a double helix carrying genetic instructions for the development, functioning, growth, and reproduction of all known organisms and many viruses.\n",
      "note: DNA is essential for inheritance, coding for proteins, and the genetic instruction guide for life and its processes.\n",
      "context: DNA is used in genetic research and forensic science.\n",
      "incorrectTerm: Deoxyribose Nucleic Acid\n"
     ]
    }
   ],
   "source": [
    "# Text Search\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "# Text Search\n",
    "query = \"DNA\"\n",
    " \n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    " \n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    select=[\"chunk\", \"note\", \"context\", \"incorrectTerm\"],\n",
    "    top=5\n",
    ")\n",
    " \n",
    "input_text = \" \"\n",
    "for result in results:  \n",
    "    # print(f\"id: {result['id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Definition: {result['chunk']}\")\n",
    "    print(f\"note: {result['note']}\")\n",
    "    print(f\"context: {result['context']}\")\n",
    "    print(f\"incorrectTerm: {result['incorrectTerm']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1b9c6be-02d7-479c-ba38-526c1be978e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5916212\n",
      "Content: Software Development is the process of conceiving, specifying, designing, programming, and testing applications and systems.\n",
      "note: Agile methodologies are popular in modern software development.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "# query = \"What can you tell me about application programming interface ?\"\n",
    "query = \"What is Agile\"\n",
    "\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=5, fields=\"text_vector\", exhaustive=True)\n",
    "# print(vector_query)\n",
    "\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"text_vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    # select=[\"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    # print(f\"id: {result['id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")\n",
    "    print(f\"note: {result['note']}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "063ffd90-bfc0-411f-8c91-e85234c8175f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Perform a hybrid search + semantic reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c62369-e119-429a-a54c-2f3dd84592da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note: Agile methodologies are popular in modern software development.\n",
      "context: It is used to create various software solutions across industries.\n",
      "incorrectTerm: Software Developement\n",
      "Reranker Score: 2.37892746925354\n",
      "Content: Software Development is the process of conceiving, specifying, designing, programming, and testing applications and systems.\n",
      "Caption: <em>Software Development </em>is the process of conceiving, specifying,<em> designing, programming, and testing applications and systems.</em> It is used to create various software solutions across industries. Agile methodologies are popular in modern<em> software development.</em> Software Developement.\n",
      "\n",
      "note: Focusing on UX can significantly improve customer satisfaction.\n",
      "context: UX is critical in product design and service delivery.\n",
      "incorrectTerm: User Experence\n",
      "Reranker Score: 1.7951167821884155\n",
      "Content: User Experience (UX) refers to a person's emotions and attitudes about using a particular product, system or service.\n",
      "Caption: User Experience (UX) refers to a person's emotions and attitudes about using a particular<em> product, system </em>or<em> service.</em> UX is critical in product design and service delivery. Focusing on UX can significantly improve customer satisfaction. User Experence.\n",
      "\n",
      "note: They enable developers to use predefined functions to build applications.\n",
      "context: APIs allow different software systems to communicate and integrate.\n",
      "incorrectTerm: Aplication Programming Interface\n",
      "Reranker Score: 1.7710129022598267\n",
      "Content: An Application Programming Interface (API) is a set of protocols and tools for building software applications.\n",
      "Caption: An<em> Application Programming Interface </em>(API) is a set of<em> protocols and tools for building software applications.</em> APIs allow different software systems to communicate and integrate. They enable developers to use predefined functions to build applications. Aplication Programming Interface.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "# Semantic Hybrid Search\n",
    "query = \" What is Agile?\"\n",
    "\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=5, fields=\"text_vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"context\", \"chunk\",  \"note\", \"incorrectTerm\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='my-semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"Semantic Answer: {answer.text}\")\n",
    "            print(f\"Semantic Answer: {answer.context}\")\n",
    "            print(f\"Semantic Answer: {answer.incorrectTerm}\")\n",
    "            print(f\"Semantic Answer: {answer.note}\")\n",
    "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    # print(f\"id: {result['id']}\")  \n",
    "    print(f\"note: {result['note']}\")\n",
    "    print(f\"context: {result['context']}\")\n",
    "    print(f\"incorrectTerm: {result['incorrectTerm']}\") \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rag_on_csv_data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
