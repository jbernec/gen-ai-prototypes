{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "258117ed-f569-4318-8f94-30f1f7b64ccb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "\n",
    "In an earlier notebook, I demonstrated how Azure AI Search can automatically convert data into vectors using the built-in vectorization feature. It can manage the entire workflow of pipeline tasks from ingestion, extraction, enrichment and data upload to the search index with minimal or no custom coding. However, a drawback is that the existing skills may not capture all the relevant content from the document.\n",
    "\n",
    "In this notebook, I demonstrate a solution that uses the prebuilt layout model of the Azure AI Document Intelligence resource to get all the necessary content from the PDF booklet and enable the semantic chunking feature. This should overcome the encountered limitation with the previous solution and improve the relevance and accuracy of the search retrieval.\n",
    "\n",
    "This is the first of two notebooks, which shows a solution that uses Azure AI Document Intelligence and Langchain to create a Retrieval Augmented Generation (RAG) workflow. It uses the Langchain Azure AI Document Intelligence document loader to get tables, paragraphs, and layout information from a PDF file. The output is in markdown format, which is processed by Langchain's markdown header splitter. This allows the semantic chunking feature of Azure AI Document Intelligence service to produce semantic chunks of the source document \n",
    "\n",
    "We employ the AI Search Python SDK to build the Azure AI Search index, load the semantically chunked documents into this index and execute a hybrid + semantic search query at the end of the notebook to assess the search result relevance.\n",
    "\n",
    "![Semantic chunking in RAG](https://github.com/jbernec/rag-orchestrations/blob/main/images/semantic-chunking.png?raw=true)\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "- An Azure AI Document Intelligence resource - follow [this document](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-4.0.0) to create one if you don't have.\n",
    "- An Azure AI Search resource - follow [this document](https://learn.microsoft.com/azure/search/search-create-service-portal) to create one if you don't have.\n",
    "- An Azure OpenAI resource and deployments for embeddings model and chat model - follow [this document](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal) to create one if you don't have.\n",
    "- I have attached a requirements file in the repo folder as this notebook to show the python libraries required for this poc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb63d4db-bfa7-48b5-8483-f5530ac96ff5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "650185d0-e0dd-413f-9871-9945e36068b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads and sets the necessary variables for Azure services.\n",
    "The variables are loaded from Azure Key Vault.\n",
    "\"\"\"\n",
    "\n",
    "azure_openai_endpoint=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\")\n",
    "azure_openai_api_key=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\")\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "azure_openai_embedding_deployment = dbutils.secrets.get(scope=\"myscope\", key=\"aoai-embedding-deployment\")\n",
    "doc_intelligence_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-endpoint\")\n",
    "doc_intelligence_key = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-key\")\n",
    "#docUrl = \"https://raw.githubusercontent.com/jbernec/rag-orchestrations/main/data/Benefit_Options.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f9880fb-f9de-4919-bbfe-2287baed6ac9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Connect to Blob Storage\n",
    "blob_connection_string = dbutils.secrets.get(scope=\"myscope\", key=\"blobstore-connstr\")\n",
    "blob_container_name = \"aisearch-rag\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "blobs = container_client.list_blobs()\n",
    "first_blob = blobs.next()\n",
    "blob_url = container_client.get_blob_client(first_blob).url\n",
    "#print(f\"URL of first blob: {blob_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "235eba57-16fb-410d-854f-495c43946236",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load a document and split it into semantic chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b5b59db-dd91-450f-b1dc-cd2ea5de3570",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of splits: 6\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Langchain Azure AI Document Intelligence loader to load the document. You can either specify file_path or url_path to load the document.\n",
    "# Ensure that the Document Intelligence managed identity is configured with SBDC RBAC on the Blob storage resource.\n",
    "loader = AzureAIDocumentIntelligenceLoader(url_path=blob_url, api_key = doc_intelligence_key, api_endpoint = doc_intelligence_endpoint, api_model=\"prebuilt-layout\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the document into semantic chunks based on markdown headers, using the MarkdownHeaderTextSplitter class.\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "docs_string = docs[0].page_content\n",
    "splits = text_splitter.split_text(docs_string)\n",
    "\n",
    "print(\"Length of splits: \" + str(len(splits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c20a4d-4c2a-4a90-a5b0-ac3b445e8818",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Document(page_content='Contoso Electronics Plan and Benefit Packages  \\n<figure>  \\n![](figures/0)  \\n<!-- FigureContent=\"Contoso Electronics\" -->  \\n</figure>  \\nThis document contains information generated using a language model (Azure OpenAI). The information contained in this document is only for demonstration purposes and does not reflect the opinions or beliefs of Microsoft. Microsoft makes no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability with respect to the information contained in this document.  \\nAll rights reserved to Microsoft  \\n<!-- PageHeader=\"Welcome to Contoso Electronics! We are excited to offer our employees two comprehensive health insurance plans through Northwind Health.\" -->')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first document in the splits list object\n",
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcdf42f7-45d3-4900-bfa8-00ed18c3fc0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Northwind Health Plus'}, page_content='Northwind Health Plus is a comprehensive plan that provides comprehensive coverage for medical, vision, and dental services. This plan also offers prescription drug coverage, mental health and substance abuse coverage, and coverage for preventive care services. With Northwind Health Plus, you can choose from a variety of in-network providers, including primary care physicians, specialists, hospitals, and pharmacies. This plan also offers coverage for emergency services, both in-network and out-of-network.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display second document in the splits list object\n",
    "splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d6b9f2f-9423-43db-b1c3-6d2c1d5a95fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Create a new index with custom filterable and retrievable fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e326bf25-cfc8-4d66-8e40-3b743a8dfdf8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the search index fields and vector search configuration\n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchField, SearchFieldDataType, VectorSearch, SimpleField, SearchableField, HnswAlgorithmConfiguration, HnswParameters, VectorSearchAlgorithmMetric, ExhaustiveKnnAlgorithmConfiguration, ExhaustiveKnnParameters, VectorSearchProfile, AzureOpenAIVectorizer, AzureOpenAIParameters, SemanticConfiguration, SemanticSearch, SemanticPrioritizedFields, SemanticField, SearchIndex\n",
    "\n",
    "search_credential = AzureKeyCredential(dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-adminkey\"))\n",
    "search_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-endpoint\")\n",
    "# Create a search index client required to create the index\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"parent_id\", key=True, type=SearchFieldDataType.String, filterable=True, sortable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, filterable=True, searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True, sortable=True, facetable=True, retrievable=True),\n",
    "    SearchableField(name=\"location\", type=SearchFieldDataType.String, searchable=True, filterable=True, retrievable=True),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, retrievable=True, hidden=False, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "]\n",
    "\n",
    "# Configure the vector search config\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),\n",
    "    ],\n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_deployment,  \n",
    "                api_key=azure_openai_api_key,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure semantic search on the index\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[\n",
    "            SemanticField(field_name=\"content\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# Create the semantic search config\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "022453df-e8b9-45a6-99e6-6909d41feb80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual-aisearch-index created\n"
     ]
    }
   ],
   "source": [
    "# Create the search index\n",
    "index_name = \"manual-aisearch-index\"\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index=index)\n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2a5a1b5-936e-44c9-9c2c-a62c106089a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Upload documents to AI Search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50432508-a888-4ffd-a03a-a7da4ad1dc33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the langchain azure open ai embedding object. This will be used to embed the vector field content\n",
    "# https://python.langchain.com/v0.1/docs/integrations/vectorstores/azuresearch/#create-embeddings-and-vector-store-instances\n",
    "\n",
    "aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2886fd30-4734-4fdc-9e8e-df31c72894c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def text_to_base64(text):\n",
    "    # Convert text to bytes using UTF-8 encoding\n",
    "    # and use this function for generating a unique value for the Azure AI Search Index parent_id values\n",
    "    bytes_data = text.encode('utf-8')\n",
    "\n",
    "    # Perform Base64 encoding\n",
    "    base64_encoded = base64.b64encode(bytes_data)\n",
    "\n",
    "    # Convert the result back to a UTF-8 string representation\n",
    "    base64_text = base64_encoded.decode('utf-8')\n",
    "\n",
    "    return base64_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ab8706e-2109-4fc8-b3f0-a87f9cbba849",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Upload the semantically chunked documents its vectors to the Azure AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1c85937-0151-4751-8e09-ab8668b4bc8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# upload data to the search index\n",
    "\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "bookname = \"Benefit_Options.pdf\"\n",
    "search_client = SearchClient(search_endpoint, index_name, credential=search_credential)\n",
    "for doc in splits:\n",
    "    try:\n",
    "        pass\n",
    "        content = doc.page_content\n",
    "        book_url = blob_url\n",
    "        upload_payload = {\n",
    "                    \"parent_id\": text_to_base64(doc.metadata.get(\"Header 1\", \"Default\") if len(doc.metadata)!=0 else \"Default\"),\n",
    "                    \"title\": doc.metadata.get(\"Header 1\", \"Default\") if len(doc.metadata)!=0 else \"Default\",\n",
    "                    \"content\": content,\n",
    "                    \"location\": book_url,\n",
    "                    \"vector\": aoai_embeddings.embed_query(content if content!=\"\" else \"-------\")\n",
    "        }\n",
    "\n",
    "        result_upload = search_client.upload_documents(documents=[upload_payload])\n",
    "        if result_upload[0].status_code != 200:\n",
    "            print(\"Status code:\",result_upload.status_code)\n",
    "            print(\"Error message:\", result_upload[0].error_message)\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50a486f2-e423-4a65-b801-ee7c2fb24c45",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Perform a hybrid search + semantic reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "140aeda0-8d67-4e66-b622-4e9fbfcff09a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: Q29zdCBDb21wYXJpc29u\nReranker Score: 3.1452205181121826\nContent: Contoso Electronics deducts the employee's portion of the healthcare cost from each paycheck. This means that the cost of the health insurance will be spread out over the course of the year, rather than being paid in one lump sum. The employee's portion of the cost will be calculated based on the selected health plan and the number of people covered by the insurance. The table below shows a cost comparison between the different health plans offered by Contoso Electronics:  \n| | Employee's cost per paycheck ||\n| | Northwind Standard | Northwind Health Plus |\n| - | - | - |\n| Employee Only | $45.00 | $55.00 |\n| Employee +1 | $65.00 | $71.00 |\n| Employee +2 or more | $78.00 | $89.00 |\nCaption: Contoso Electronics deducts the employee's portion of the healthcare cost from each paycheck. This means that the cost of the health insurance will be spread out over the course of the year, rather than being paid in one lump sum. The employee's portion of the cost will be calculated based on the selected health plan and the number of people covered by the insurance. The table below shows a cost comparison between the different health plans offered by Contoso Electronics:  \n| | Employee's cost per paycheck ||\n| | Northwind Standard | Northwind Health Plus |\n| - | - | - |\n| Employee Only | $45.00 | $55.00 |\n| Employee +1 | $65.00 | $71.00 |\n| Employee +2 or more | $78.00 | $89.00 |.\n\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Semantic Hybrid Search\n",
    "# query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"\n",
    "query = \"How much is the employee's cost per pay check for the north wind standard?\"\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, search_credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"content\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='my-semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=1\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"Semantic Answer: {answer.text}\")\n",
    "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"parent_id: {result['parent_id']}\")   \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rag_search_index_ingestion",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
