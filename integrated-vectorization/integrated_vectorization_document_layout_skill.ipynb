{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36bb9bfe-65b0-49ae-bff9-f8f2a45ec9bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### In this notebook I demonstrate the use of the Azure AI Search Integrated Vectorization feature. I utilize the following skills and prerequisites\n",
    "* Document Layout skill to extract data from a sample PDF file in Azure Blob storage \n",
    "* https://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-document-intelligence-layout\n",
    "* https://learn.microsoft.com/en-us/azure/search/search-how-to-semantic-chunking\n",
    "* SplitSkill to chunk the data\n",
    "* OCR skill to add page numbers for every chunk that is extracted\n",
    "* Deploy the following services in the same region; Azure AI Document Intelligence, Azure AI Search, Azure Open AI, AI Foundry, Azure Blob Storage\n",
    "* Enable system assigned managed identity\n",
    "* Deploy text-embedding-3-small on Azure OpenAI (in Azure AI Foundry) for embeddings\n",
    "* Deploy gpt-4o on Azure OpenAI for chat completion\n",
    "* Configure search engine RBAC to Azure Blob Storage by adding a role for Storage Blob Data Reader, assigned to the search service system-managed identity\n",
    "* Configure search engine RBAC to Azure Open AI by adding a role for Cognitive Services OpenAI User, assigned to the search service system-managed identity\n",
    "* The model names and endpoint should be saved in AKV. Embedding skills and vectorizers assemble the full endpoint internally, so only the resource URI is needed. For example, given https://MY-FAKE-ACCOUNT.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-06-01, the endpoint should to be provided in skill and vectorizer definitions is https://MY-FAKE-ACCOUNT.openai.azure.com.\n",
    "* The Azure AI multiservice account is used for skills processing. The multiservice account key must be provided, even if RBAC is in use. The key isn't used on the connection, but it's currently used for billing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b49d8507-cef3-4dd7-a839-90785e45efef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d7131c8-493d-4ec8-aa00-92245f8f6035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "import azure.identity\n",
    "from azure.identity import DefaultAzureCredential, EnvironmentCredential, ManagedIdentityCredential, SharedTokenCacheCredential\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, AnalyzeDocumentRequest, ContentFormat\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration, SemanticSearch, SemanticPrioritizedFields, SemanticField\n",
    ")\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "import os\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.identity import DefaultAzureCredential, AzureAuthorityHosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42ed4eaa-5b15-4477-bb61-d0ef8a804d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define Required Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a658011-70c3-4a56-a0cf-6aed3b154194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads and sets the necessary variables for Azure services.\n",
    "The variables are loaded from Azure Key Vault.\n",
    "\"\"\"\n",
    "azure_openai_endpoint=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\")\n",
    "azure_openai_api_key=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\")\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "azure_openai_embedding_deployment = dbutils.secrets.get(scope=\"myscope\", key=\"aoai-embedding-deployment\")\n",
    "azure_openai_embedding_model = dbutils.secrets.get(scope=\"myscope\", key=\"aoai-embedding-model\")\n",
    "azure_openai_vector_dimension = 1536\n",
    "doc_intelligence_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-endpoint\")\n",
    "doc_intelligence_key = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-key\")\n",
    "search_credential = AzureKeyCredential(dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-key\"))\n",
    "search_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-endpoint\")\n",
    "index_name = \"integrated-vector-layout-index\"\n",
    "data_source_connection_name = \"iv-indexer-datasource-connection\"\n",
    "azure_ai_services_key = dbutils.secrets.get(scope=\"myscope\", key=\"azure-ai-services-key\")\n",
    "azure_ai_services_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"azure-ai-services-endpoint\")\n",
    "\n",
    "# Connect to Blob Storage\n",
    "# blob_connection_string = dbutils.secrets.get(scope=\"myscope\", key=\"blobstore-connstr\")\n",
    "# blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "\n",
    "# Service principal authentication variables\n",
    "tenant_id=dbutils.secrets.get(scope=\"myscope\", key=\"tenantid\")\n",
    "client_id = dbutils.secrets.get(scope=\"myscope\", key=\"clientid\")\n",
    "client_secret = dbutils.secrets.get(scope=\"myscope\", key=\"clientsecret\")\n",
    "credential = azure.identity.ClientSecretCredential(tenant_id=tenant_id, client_id=client_id, client_secret=client_secret)\n",
    "\n",
    "blob_storage_name = \"blobstore05\" #dbutils.secrets.get(scope=\"myscope\", key=\"blobstore-account-name\")\n",
    "# Use the above defined service principal to authenticate against the blob storage endpoint of the ADLS Gen 2 service\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{blob_storage_name}.blob.core.windows.net\",\n",
    "    credential=credential\n",
    ")\n",
    "blob_container_name = \"integrated-vectorization\"\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "use_layout = True\n",
    "document_layout_depth = \"h3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865392b6-e124-4ac8-85d6-320c8489743a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Azure AI Search Datasource Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc31b92d-7ca5-475c-8544-5c8ceaaa224f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source iv-indexer-datasource-connection created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataIdentity,\n",
    "    SearchIndexerDataUserAssignedIdentity,\n",
    "    SearchIndexerDataNoneIdentity\n",
    ")\n",
    "from azure.search.documents.indexes.models import (\n",
    "    NativeBlobSoftDeleteDeletionDetectionPolicy,\n",
    "    HighWaterMarkChangeDetectionPolicy,\n",
    "    DataChangeDetectionPolicy\n",
    ")\n",
    "\n",
    "indexer_client = SearchIndexerClient(\n",
    "    endpoint=search_endpoint, credential=search_credential\n",
    ")\n",
    "indexer_container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(name=data_source_connection_name, connection_string= dbutils.secrets.get(scope=\"myscope\", key=\"blobstore-connstr\"), container=indexer_container, data_deletion_detection_policy=NativeBlobSoftDeleteDeletionDetectionPolicy(), type=\"azureblob\")\n",
    "\n",
    "# Create the data source object\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection=data_source_connection)\n",
    "\n",
    "print(f\"Data source {data_source.name} created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dd4c984-9d0e-4c65-90b8-b830be4727e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Azure AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3bc09c0-3339-4c83-a38b-5719184a7093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fields = [\n",
    "    SearchField(name=\"parent_id\",type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"title\",type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"chunk\",type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),\n",
    "    SearchField(name=\"vector\",type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_vector_dimension, vector_search_profile_name=\"myHnswProfile\")\n",
    "]\n",
    "\n",
    "if use_layout:\n",
    "    fields.extend([\n",
    "        SearchField(name=\"header_1\",type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),\n",
    "        SearchField(name=\"header_2\",type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),\n",
    "        SearchField(name=\"header_3\",type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),\n",
    "    ])\n",
    "\n",
    "\n",
    "# Define the vector search configuration and parameters\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(name=\"myHsnw\")\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHsnw\",\n",
    "            vectorizer_name=\"myOpenAI\"\n",
    "        )\n",
    "    ],\n",
    "    vectorizers=[\n",
    "        AzureOpenAIVectorizer(\n",
    "            vectorizer_name=\"myOpenAI\",\n",
    "            kind=\"azureOpenAI\",\n",
    "            parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_embedding_deployment,\n",
    "                model_name=azure_openai_embedding_model,\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure semantic search on the index\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic search config\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "scoring_profiles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c35313-e690-40ca-ba9f-d25a4339737e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integrated-vector-layout-index created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index client required to create the index\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, scoring_profiles=scoring_profiles, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index=index)\n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e26ae82-b593-43c7-ab2d-2931bd7cd642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> #### Create Required Skillsets for the document extraction processes and operations.\n",
    "Skills drive integrated vectorization. Text Split provides data chunking. AzureOpenAIEmbedding handles calls to Azure OpenAI, using the connection information you provide in the environment variables. An indexer projection specifies secondary indexes used for chunked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd41d6f0-bc50-4ab6-adee-1037af8e6c72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created skillset integrated-vector-layout-index-skillset\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    OcrSkill,\n",
    "    SearchIndexerSkillset,\n",
    "    DocumentIntelligenceLayoutSkill,\n",
    "    DocumentIntelligenceLayoutSkillMarkdownHeaderDepth,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    AIServicesAccountKey,\n",
    "    AIServicesAccountIdentity\n",
    ")\n",
    "\n",
    "skillset_name = f\"{index_name}-skillset\"\n",
    "\n",
    "def create_layout_skillset():\n",
    "    layout_skill = DocumentIntelligenceLayoutSkill(\n",
    "        description=\"Extracts layout information from the document\",\n",
    "        context=\"/document\",\n",
    "        output_mode=\"oneToMany\",\n",
    "        markdown_header_depth=document_layout_depth,\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(name=\"file_data\", source=\"/document/file_data\"),\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"markdown_document\", target_name=\"markdownDocument\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    split_skill = SplitSkill(\n",
    "        description=\"Split skill to chunk documents\",\n",
    "        text_split_mode=\"pages\",\n",
    "        context=\"/document/markdownDocument/*\",\n",
    "        maximum_page_length=2000,\n",
    "        page_overlap_length=500,\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/markdownDocument/*/content\"),\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    embedding_skill = AzureOpenAIEmbeddingSkill(\n",
    "        description=\"Skill to generate embeddings via Azure OpenAI\",\n",
    "        context=\"/document/markdownDocument/*/pages/*\",\n",
    "        resource_url=azure_openai_endpoint,\n",
    "        deployment_name=azure_openai_embedding_deployment,\n",
    "        model_name=azure_openai_embedding_model,\n",
    "        dimensions=azure_openai_vector_dimension,\n",
    "        api_key=azure_openai_api_key,\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/markdownDocument/*/pages/*\"),\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    index_projections = SearchIndexerIndexProjection(\n",
    "        selectors=[\n",
    "            SearchIndexerIndexProjectionSelector(\n",
    "                target_index_name=index_name,\n",
    "                parent_key_field_name=\"parent_id\",\n",
    "                source_context=\"/document/markdownDocument/*/pages/*\",\n",
    "                mappings=[\n",
    "                    InputFieldMappingEntry(name=\"chunk\", source=\"/document/markdownDocument/*/pages/*\"),\n",
    "                    InputFieldMappingEntry(name=\"vector\", source=\"/document/markdownDocument/*/pages/*/vector\"),\n",
    "                    InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
    "                    InputFieldMappingEntry(name=\"header_1\", source=\"/document/markdownDocument/*/sections/h1\"),\n",
    "                    InputFieldMappingEntry(name=\"header_2\", source=\"/document/markdownDocument/*/sections/h2\"),\n",
    "                    InputFieldMappingEntry(name=\"header_3\", source=\"/document/markdownDocument/*/sections/h3\"),\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        parameters=SearchIndexerIndexProjectionsParameters(\n",
    "            projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
    "        )\n",
    "    )\n",
    "\n",
    "    skills = [layout_skill, split_skill, embedding_skill]\n",
    "\n",
    "    return SearchIndexerSkillset(\n",
    "        name=skillset_name,\n",
    "        description=\"Skillset to chunk documents and generating embeddings\",\n",
    "        skills=skills,\n",
    "        index_projection=index_projections,\n",
    "        cognitive_services_account=AIServicesAccountKey(key=azure_ai_services_key, subdomain_url=azure_ai_services_endpoint)\n",
    "    )\n",
    "\n",
    "def create_skillset():\n",
    "    split_skill = SplitSkill(\n",
    "        description=\"Skill to split document text into smaller manageable chunks\",\n",
    "        text_split_mode=\"pages\",\n",
    "        context=\"/document\",\n",
    "        maximum_page_length=2000,\n",
    "        page_overlap_length=500,\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    embedding_skill = AzureOpenAIEmbeddingSkill(\n",
    "        description=\"Skill used to generate embeddings via Azure Open AI embedding model\",\n",
    "        context=\"/document/pages/*\",\n",
    "        resource_url=azure_openai_endpoint,\n",
    "        deployment_name=azure_openai_embedding_deployment,\n",
    "        model_name=azure_openai_embedding_model,\n",
    "        dimensions=azure_openai_vector_dimension,\n",
    "        api_key=azure_openai_api_key,\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    index_projections = SearchIndexerIndexProjection(\n",
    "        selectors=[\n",
    "            SearchIndexerIndexProjectionSelector(\n",
    "                target_index_name=index_name,\n",
    "                parent_key_field_name=\"parent_id\",\n",
    "                source_context=\"/document/pages/*\",\n",
    "                mappings=[\n",
    "                    InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),\n",
    "                    InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),\n",
    "                    InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        parameters=SearchIndexerIndexProjectionsParameters(\n",
    "            projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
    "        )\n",
    "    )\n",
    "\n",
    "    skills = [split_skill, embedding_skill]\n",
    "\n",
    "    return SearchIndexerSkillset(\n",
    "        name=skillset_name,\n",
    "        skills=skills,\n",
    "        index_projection=index_projections,\n",
    "        description=\"Skillset that enables doc chunking and generating embeddings\",\n",
    "        cognitive_services_account=AIServicesAccountKey(key=azure_ai_services_key, subdomain_url=azure_ai_services_endpoint)\n",
    "    )\n",
    "\n",
    "if use_layout:\n",
    "    skillset = create_layout_skillset()\n",
    "else:\n",
    "    skillset = create_skillset()\n",
    "\n",
    "indexer_client.create_or_update_skillset(skillset)\n",
    "print(f\"Created skillset {skillset.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dffdb37-f3a7-45f6-8c80-ee5f45dc7536",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DocumentIntelligenceLayoutSkill in module azure.search.documents.indexes._generated.models._models_py3:\n\nclass DocumentIntelligenceLayoutSkill(SearchIndexerSkill)\n |  DocumentIntelligenceLayoutSkill(*, inputs: List[ForwardRef('_models.InputFieldMappingEntry')], outputs: List[ForwardRef('_models.OutputFieldMappingEntry')], name: Optional[str] = None, description: Optional[str] = None, context: Optional[str] = None, output_mode: Union[str, ForwardRef('_models.DocumentIntelligenceLayoutSkillOutputMode')] = 'oneToMany', markdown_header_depth: Union[str, ForwardRef('_models.DocumentIntelligenceLayoutSkillMarkdownHeaderDepth')] = 'h6', **kwargs: Any) -> None\n |  \n |  A skill that extracts content and layout information (as markdown), via Azure AI Services, from\n |  files within the enrichment pipeline.\n |  \n |  All required parameters must be populated in order to send to server.\n |  \n |  :ivar odata_type: A URI fragment specifying the type of skill. Required.\n |  :vartype odata_type: str\n |  :ivar name: The name of the skill which uniquely identifies it within the skillset. A skill\n |   with no name defined will be given a default name of its 1-based index in the skills array,\n |   prefixed with the character '#'.\n |  :vartype name: str\n |  :ivar description: The description of the skill which describes the inputs, outputs, and usage\n |   of the skill.\n |  :vartype description: str\n |  :ivar context: Represents the level at which operations take place, such as the document root\n |   or document content (for example, /document or /document/content). The default is /document.\n |  :vartype context: str\n |  :ivar inputs: Inputs of the skills could be a column in the source data set, or the output of\n |   an upstream skill. Required.\n |  :vartype inputs: list[~azure.search.documents.indexes.models.InputFieldMappingEntry]\n |  :ivar outputs: The output of a skill is either a field in a search index, or a value that can\n |   be consumed as an input by another skill. Required.\n |  :vartype outputs: list[~azure.search.documents.indexes.models.OutputFieldMappingEntry]\n |  :ivar output_mode: Controls the cardinality of the output produced by the skill. Default is\n |   'oneToMany'. \"oneToMany\"\n |  :vartype output_mode: str or\n |   ~azure.search.documents.indexes.models.DocumentIntelligenceLayoutSkillOutputMode\n |  :ivar markdown_header_depth: The depth of headers in the markdown output. Default is h6. Known\n |   values are: \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", and \"h6\".\n |  :vartype markdown_header_depth: str or\n |   ~azure.search.documents.indexes.models.DocumentIntelligenceLayoutSkillMarkdownHeaderDepth\n |  \n |  Method resolution order:\n |      DocumentIntelligenceLayoutSkill\n |      SearchIndexerSkill\n |      azure.search.documents.indexes._generated._serialization.Model\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, *, inputs: List[ForwardRef('_models.InputFieldMappingEntry')], outputs: List[ForwardRef('_models.OutputFieldMappingEntry')], name: Optional[str] = None, description: Optional[str] = None, context: Optional[str] = None, output_mode: Union[str, ForwardRef('_models.DocumentIntelligenceLayoutSkillOutputMode')] = 'oneToMany', markdown_header_depth: Union[str, ForwardRef('_models.DocumentIntelligenceLayoutSkillMarkdownHeaderDepth')] = 'h6', **kwargs: Any) -> None\n |      :keyword name: The name of the skill which uniquely identifies it within the skillset. A skill\n |       with no name defined will be given a default name of its 1-based index in the skills array,\n |       prefixed with the character '#'.\n |      :paramtype name: str\n |      :keyword description: The description of the skill which describes the inputs, outputs, and\n |       usage of the skill.\n |      :paramtype description: str\n |      :keyword context: Represents the level at which operations take place, such as the document\n |       root or document content (for example, /document or /document/content). The default is\n |       /document.\n |      :paramtype context: str\n |      :keyword inputs: Inputs of the skills could be a column in the source data set, or the output\n |       of an upstream skill. Required.\n |      :paramtype inputs: list[~azure.search.documents.indexes.models.InputFieldMappingEntry]\n |      :keyword outputs: The output of a skill is either a field in a search index, or a value that\n |       can be consumed as an input by another skill. Required.\n |      :paramtype outputs: list[~azure.search.documents.indexes.models.OutputFieldMappingEntry]\n |      :keyword output_mode: Controls the cardinality of the output produced by the skill. Default is\n |       'oneToMany'. \"oneToMany\"\n |      :paramtype output_mode: str or\n |       ~azure.search.documents.indexes.models.DocumentIntelligenceLayoutSkillOutputMode\n |      :keyword markdown_header_depth: The depth of headers in the markdown output. Default is h6.\n |       Known values are: \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", and \"h6\".\n |      :paramtype markdown_header_depth: str or\n |       ~azure.search.documents.indexes.models.DocumentIntelligenceLayoutSkillMarkdownHeaderDepth\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __annotations__ = {}\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from azure.search.documents.indexes._generated._serialization.Model:\n |  \n |  __eq__(self, other: Any) -> bool\n |      Compare objects by comparing all attributes.\n |      \n |      :param object other: The object to compare\n |      :returns: True if objects are equal\n |      :rtype: bool\n |  \n |  __ne__(self, other: Any) -> bool\n |      Compare objects by comparing all attributes.\n |      \n |      :param object other: The object to compare\n |      :returns: True if objects are not equal\n |      :rtype: bool\n |  \n |  __str__(self) -> str\n |      Return str(self).\n |  \n |  as_dict(self, keep_readonly: bool = True, key_transformer: Callable[[str, Dict[str, Any], Any], Any] = <function attribute_transformer at 0x7f9754c98a40>, **kwargs: Any) -> MutableMapping[str, Any]\n |      Return a dict that can be serialized using json.dump.\n |      \n |      Advanced usage might optionally use a callback as parameter:\n |      \n |      .. code::python\n |      \n |          def my_key_transformer(key, attr_desc, value):\n |              return key\n |      \n |      Key is the attribute name used in Python. Attr_desc\n |      is a dict of metadata. Currently contains 'type' with the\n |      msrest type and 'key' with the RestAPI encoded key.\n |      Value is the current value in this object.\n |      \n |      The string returned will be used to serialize the key.\n |      If the return type is a list, this is considered hierarchical\n |      result dict.\n |      \n |      See the three examples in this file:\n |      \n |      - attribute_transformer\n |      - full_restapi_key_transformer\n |      - last_restapi_key_transformer\n |      \n |      If you want XML serialization, you can pass the kwargs is_xml=True.\n |      \n |      :param bool keep_readonly: If you want to serialize the readonly attributes\n |      :param function key_transformer: A key transformer function.\n |      :returns: A dict JSON compatible object\n |      :rtype: dict\n |  \n |  serialize(self, keep_readonly: bool = False, **kwargs: Any) -> MutableMapping[str, Any]\n |      Return the JSON that would be sent to server from this model.\n |      \n |      This is an alias to `as_dict(full_restapi_key_transformer, keep_readonly=False)`.\n |      \n |      If you want XML serialization, you can pass the kwargs is_xml=True.\n |      \n |      :param bool keep_readonly: If you want to serialize the readonly attributes\n |      :returns: A dict JSON compatible object\n |      :rtype: dict\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from azure.search.documents.indexes._generated._serialization.Model:\n |  \n |  deserialize(data: Any, content_type: Optional[str] = None) -> ~ModelType from builtins.type\n |      Parse a str using the RestAPI syntax and return a model.\n |      \n |      :param str data: A str using RestAPI structure. JSON by default.\n |      :param str content_type: JSON by default, set application/xml if XML.\n |      :returns: An instance of this model\n |      :raises DeserializationError: if something went wrong\n |      :rtype: ModelType\n |  \n |  enable_additional_properties_sending() -> None from builtins.type\n |  \n |  from_dict(data: Any, key_extractors: Optional[Callable[[str, Dict[str, Any], Any], Any]] = None, content_type: Optional[str] = None) -> ~ModelType from builtins.type\n |      Parse a dict using given key extractor return a model.\n |      \n |      By default consider key\n |      extractors (rest_key_case_insensitive_extractor, attribute_key_case_insensitive_extractor\n |      and last_rest_key_case_insensitive_extractor)\n |      \n |      :param dict data: A dict using RestAPI structure\n |      :param function key_extractors: A key extractor function.\n |      :param str content_type: JSON by default, set application/xml if XML.\n |      :returns: An instance of this model\n |      :raises DeserializationError: if something went wrong\n |      :rtype: ModelType\n |  \n |  is_xml_model() -> bool from builtins.type\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from azure.search.documents.indexes._generated._serialization.Model:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from azure.search.documents.indexes._generated._serialization.Model:\n |  \n |  __hash__ = None\n\n"
     ]
    }
   ],
   "source": [
    "help(DocumentIntelligenceLayoutSkill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b4c4574-5ae6-4ad1-ad5f-d2a37a2cd69e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7008d8d8-dc12-4b0d-9a18-73f2020d38e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " integrated-vector-layout-index-indexer is created and running. If queries return no results, please wait a bit and try again.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    BlobIndexerImageAction\n",
    ")\n",
    "\n",
    "# Define indexer name  \n",
    "indexer_name = f\"{index_name}-indexer\"\n",
    "\n",
    "index_parameters = None\n",
    "if use_layout:\n",
    "  index_parameters = IndexingParameters(\n",
    "    configuration=IndexingParametersConfiguration(\n",
    "      allow_skillset_to_read_file_data=True,\n",
    "      query_timeout=None,\n",
    "    )\n",
    "  )\n",
    "\n",
    "indexer = SearchIndexer(\n",
    "  name=indexer_name,\n",
    "  description=\"Indexer to orchestrate the document indexing and embedding generation\",\n",
    "  skillset_name=skillset_name,\n",
    "  target_index_name=index_name,\n",
    "  data_source_name=data_source.name,\n",
    "  parameters=index_parameters\n",
    ")\n",
    "\n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)\n",
    "\n",
    "# Run the indexer to kick off the indexing process\n",
    "indexer_client.run_indexer(indexer_name)\n",
    "print(f' {indexer_name} is created and running. If queries return no results, please wait a bit and try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c659d974-38e9-490e-b5cb-051039d2282f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Perform a vector similarity search\n",
    "\n",
    "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization.\n",
    "\n",
    "If you indexed the health plan PDF file, send queries that ask plan-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1b9c6be-02d7-479c-ba38-526c1be978e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9ibG9ic3RvcmUwNS5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50ZWdyYXRlZC12ZWN0b3JpemF0aW9uL0JlbmVmaXRfT3B0aW9ucy5wZGY1\nchunk_id: 9cf44e99b2e2_aHR0cHM6Ly9ibG9ic3RvcmUwNS5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50ZWdyYXRlZC12ZWN0b3JpemF0aW9uL0JlbmVmaXRfT3B0aW9ucy5wZGY1_markdownDocument_3_pages_0\nScore: 0.814661\nContent: Both plans offer coverage for routine physicals, well-child visits, immunizations, and other preventive\r\ncare services. The plans also cover preventive care services such as mammograms, colonoscopies, and\r\nother cancer screenings.\r\n\r\nNorthwind Health Plus offers more comprehensive coverage than Northwind Standard. This plan offers\r\ncoverage for emergency services, both in-network and out-of-network, as well as mental health and\r\nsubstance abuse coverage. Northwind Standard does not offer coverage for emergency services, mental\r\nhealth and substance abuse coverage, or out-of-network services.\r\n\r\nBoth plans offer coverage for prescription drugs. Northwind Health Plus offers a wider range of\r\nprescription drug coverage than Northwind Standard. Northwind Health Plus covers generic, brand-\r\nname, and specialty drugs, while Northwind Standard only covers generic and brand-name drugs.\r\n\r\nBoth plans offer coverage for vision and dental services. Northwind Health Plus offers coverage for vision\r\nexams, glasses, and contact lenses, as well as dental exams, cleanings, and fillings. Northwind Standard\r\nonly offers coverage for vision exams and glasses.\r\n\r\nBoth plans offer coverage for medical services. Northwind Health Plus offers coverage for hospital stays,\r\ndoctor visits, lab tests, and X-rays. Northwind Standard only offers coverage for doctor visits and lab\r\ntests.\r\n\r\nNorthwind Health Plus is a comprehensive plan that offers more coverage than Northwind Standard.\r\nNorthwind Health Plus offers coverage for emergency services, mental health and substance abuse\r\ncoverage, and out-of-network services, while Northwind Standard does not. Northwind Health Plus also\r\n\r\n<!-- PageBreak -->\r\n\r\noffers a wider range of prescription drug coverage than Northwind Standard. Both plans offer coverage\r\nfor vision and dental services, as well as medical services.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"\n",
    "\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5bba0c-aee8-46a3-b11a-1bdc9053d8f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9ibG9ic3RvcmUwNS5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50ZWdyYXRlZC12ZWN0b3JpemF0aW9uL0JlbmVmaXRfT3B0aW9ucy5wZGY1\nchunk_id: 9cf44e99b2e2_aHR0cHM6Ly9ibG9ic3RvcmUwNS5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50ZWdyYXRlZC12ZWN0b3JpemF0aW9uL0JlbmVmaXRfT3B0aW9ucy5wZGY1_markdownDocument_4_pages_0\nScore: 0.7760778\nContent: Contoso Electronics deducts the employee's portion of the healthcare cost from each paycheck. This\r\nmeans that the cost of the health insurance will be spread out over the course of the year, rather\r\nthan being paid in one lump sum. The employee's portion of the cost will be calculated based on the\r\nselected health plan and the number of people covered by the insurance. The table below shows a\r\ncost comparison between the different health plans offered by Contoso Electronics:\r\n\r\n\r\n<table>\r\n<tr>\r\n<th rowspan=\"2\"></th>\r\n<th colspan=\"2\">Employee's cost per paycheck</th>\r\n</tr>\r\n<tr>\r\n<th>Northwind Standard</th>\r\n<th>Northwind Health Plus</th>\r\n</tr>\r\n<tr>\r\n<td>Employee Only</td>\r\n<td>$45.00</td>\r\n<td>$55.00</td>\r\n</tr>\r\n<tr>\r\n<td>Employee +1</td>\r\n<td>$65.00</td>\r\n<td>$71.00</td>\r\n</tr>\r\n<tr>\r\n<td>Employee +2 or more</td>\r\n<td>$78.00</td>\r\n<td>$89.00</td>\r\n</tr>\r\n</table>\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"How much is the employee's cost per pay check for the Northwind Health Plus?\"\n",
    "\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "063ffd90-bfc0-411f-8c91-e85234c8175f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Perform a hybrid search + semantic reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c62369-e119-429a-a54c-2f3dd84592da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Answer: Contoso Electronics deducts the employee's portion of the healthcare... The table below shows a cost comparison between the different health plans offered by Contoso Electronics:      Employee's cost per paycheck<em>   Northwind Standard Northwind Health Plus </em>  Employee Only $45.00 $55.00   Employee +1 $65.00 $71.00   Employee +2 or more $78.00 $89.00.\nSemantic Answer Score: 0.9549999833106995\n\nparent_id: aHR0cHM6Ly9ibG9ic3RvcmUwNS5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50ZWdyYXRlZC12ZWN0b3JpemF0aW9uL0JlbmVmaXRfT3B0aW9ucy5wZGY1\nchunk_id: 9cf44e99b2e2_aHR0cHM6Ly9ibG9ic3RvcmUwNS5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50ZWdyYXRlZC12ZWN0b3JpemF0aW9uL0JlbmVmaXRfT3B0aW9ucy5wZGY1_markdownDocument_3_pages_0\nReranker Score: 3.4568681716918945\nContent: Both plans offer coverage for routine physicals, well-child visits, immunizations, and other preventive\r\ncare services. The plans also cover preventive care services such as mammograms, colonoscopies, and\r\nother cancer screenings.\r\n\r\nNorthwind Health Plus offers more comprehensive coverage than Northwind Standard. This plan offers\r\ncoverage for emergency services, both in-network and out-of-network, as well as mental health and\r\nsubstance abuse coverage. Northwind Standard does not offer coverage for emergency services, mental\r\nhealth and substance abuse coverage, or out-of-network services.\r\n\r\nBoth plans offer coverage for prescription drugs. Northwind Health Plus offers a wider range of\r\nprescription drug coverage than Northwind Standard. Northwind Health Plus covers generic, brand-\r\nname, and specialty drugs, while Northwind Standard only covers generic and brand-name drugs.\r\n\r\nBoth plans offer coverage for vision and dental services. Northwind Health Plus offers coverage for vision\r\nexams, glasses, and contact lenses, as well as dental exams, cleanings, and fillings. Northwind Standard\r\nonly offers coverage for vision exams and glasses.\r\n\r\nBoth plans offer coverage for medical services. Northwind Health Plus offers coverage for hospital stays,\r\ndoctor visits, lab tests, and X-rays. Northwind Standard only offers coverage for doctor visits and lab\r\ntests.\r\n\r\nNorthwind Health Plus is a comprehensive plan that offers more coverage than Northwind Standard.\r\nNorthwind Health Plus offers coverage for emergency services, mental health and substance abuse\r\ncoverage, and out-of-network services, while Northwind Standard does not. Northwind Health Plus also\r\n\r\n<!-- PageBreak -->\r\n\r\noffers a wider range of prescription drug coverage than Northwind Standard. Both plans offer coverage\r\nfor vision and dental services, as well as medical services.\nCaption: The plans also cover preventive care services such as mammograms, colonoscopies, and other cancer screenings. <em>Northwind Health Plus </em>offers<em> more comprehensive coverage than Northwind Standard.</em> This plan offers coverage for emergency services, both in-network and out-of-network, as well as mental health and substance abuse coverage. Northwind Health.\n\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "# Semantic Hybrid Search\n",
    "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"\n",
    "\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='my-semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=1\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"Semantic Answer: {answer.text}\")\n",
    "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "integrated_vectorization_document_layout_skill",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
